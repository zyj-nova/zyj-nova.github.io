<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="天空如此辽阔，大地不过是必经之路" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     张永剑的博客
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>


  

  

<link rel="alternate" href="/atom.xml" title="张永剑的博客" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    <main class="content">
      
<div id="main">
  <section class="outer">
  <article class="articles">
    
    
    
    
    <article id="post-SpringMVC源码浅析" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/24/SpringMVC%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/"
    >SpringMVC源码浅析</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/24/SpringMVC%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/" class="article-date">
  <time datetime="2020-06-24T01:47:29.672Z" itemprop="datePublished">2020-06-24</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="SpringMVC源码浅析"><a href="#SpringMVC源码浅析" class="headerlink" title="SpringMVC源码浅析"></a>SpringMVC源码浅析</h2>
      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-生成对抗网络" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/22/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/"
    >生成对抗网络</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/22/%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/" class="article-date">
  <time datetime="2020-06-22T05:22:08.407Z" itemprop="datePublished">2020-06-22</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="生成对抗网络（GAN）"><a href="#生成对抗网络（GAN）" class="headerlink" title="生成对抗网络（GAN）"></a>生成对抗网络（GAN）</h2><h3 id="1-入门简介"><a href="#1-入门简介" class="headerlink" title="1. 入门简介"></a>1. 入门简介</h3><p>​        gan整体的损失函数</p>
<script type="math/tex; mode=display">
\min_{G}\max_{D} V(G,D) = E_{x-P_{data}}\log D(x) + E_{z-P_z}\log (1-D(G(z)))</script><p>​        训练时，先训练Discriminator、然后训练Generator，迭代直至目标函数收敛。</p>
<p>​        需要注意的是，一切损失计算都是在D（判别器）输出处产生的，而D的输出一般是fake/true的判断，所以整体上采用的是二分类交叉熵函数。</p>
<p>​        首先看一下maxD部分，因为训练一般是先保持G（生成器）不变训练D的。D的训练目标是正确区分fake/true，如果我们以1/0代表true/fake，则对第一项E因为输入采样自真实数据所以我们期望D(x)趋近于1，也就是第一项更大。同理第二项E输入采样自G生成数据，所以我们期望D(G(z))趋近于0更好，也就是说第二项又是更大。所以是这一部分是期望训练使得整体更大了，也就是<code>maxD</code>的含义了。</p>
<p>　　第二部分<strong>保持D不变，训练G</strong>，这个时候只有第二项E有用了，<strong>关键来了，因为我们要迷惑D，所以这时将label设置为1(我们知道是fake，所以才叫迷惑)，希望D(G(z))输出接近于1，也就是这一项越小越好，这就是minG。当然判别器D哪有这么好糊弄，所以这个时候判别器就会产生比较大的误差，误差会更新G，那么G就会变得更好了，这次没有骗过你，只能下次更努力了</strong>。</p>
<p>​        Discriminator的损失函数</p>
<script type="math/tex; mode=display">
\max_D \log [D(x)] + \log [1 - D(G(z))]</script><p>​        Generator的损失函数</p>
<script type="math/tex; mode=display">
\min_G \log[1-D(G(z))]</script><p>​        <strong>在（近似）最优判别器下，最小化生成器的loss等价于最小化$P_r$与$P_g$之间的JS散度</strong>。</p>
<p>​        下图中可以发现，所有的loss都是由判别器产生的。如果没有D，G不知道自己生成的结果如何，便得不到权重更新。</p>
<p>​    <img src="E:\hexo\themes\ayer\source\images\gan-train.png" alt="image-20200625214641466"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets,transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br><span class="line"></span><br><span class="line">device = torch.device(<span class="string">'cuda'</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">'cpu'</span>)</span><br><span class="line"><span class="comment">#数据集的加载</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Lambda(<span class="keyword">lambda</span> x: x.repeat(<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">    transforms.Normalize(mean=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), std=(<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line">train_dataset = datasets.MNIST(root=<span class="string">'./MNIST_data/'</span>, train=<span class="literal">True</span>, transform=transform, download=<span class="literal">False</span>)</span><br><span class="line">test_dataset = datasets.MNIST(root=<span class="string">'./MNIST_data/'</span>, train=<span class="literal">False</span>, transform=transform, download=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_dims, output_dims)</span>:</span></span><br><span class="line">        super(Generator,self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dims,<span class="number">256</span>)</span><br><span class="line">        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*<span class="number">2</span>)</span><br><span class="line">        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*<span class="number">2</span>)</span><br><span class="line">        self.fc4 = nn.Linear(self.fc3.out_features, output_dims)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.leaky_relu(self.fc1(x),<span class="number">0.2</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc2(x),<span class="number">0.3</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc3(x),<span class="number">0.4</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.tanh(self.fc4(x))</span><br><span class="line">    </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,input_dim)</span>:</span></span><br><span class="line">        super(Discriminator,self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(input_dim, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//<span class="number">2</span>)</span><br><span class="line">        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//<span class="number">2</span>)</span><br><span class="line">        self.fc4 = nn.Linear(self.fc3.out_features, <span class="number">1</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.leaky_relu(self.fc1(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc2(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc3(x), <span class="number">0.2</span>)</span><br><span class="line">        x = F.dropout(x, <span class="number">0.3</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.sigmoid(self.fc4(x))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 二分类交叉熵损失函数</span></span><br><span class="line">criterion = nn.BCELoss()</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.0002</span></span><br><span class="line">D_optimizer = optim.Adam(D.parameters(), lr = lr)</span><br><span class="line">G_optimizer = optim.Adam(G.parameters(), lr = lr)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">G_train</span><span class="params">(x)</span>:</span></span><br><span class="line">    G.zero_grad()</span><br><span class="line">    z = Variable(torch.randn(batch_size,z_dim).to(device))</span><br><span class="line">    <span class="comment"># label全为1</span></span><br><span class="line">    y = Variable(torch.ones(batch_size,<span class="number">1</span>).to(device))</span><br><span class="line">    </span><br><span class="line">    G_output = G(z)</span><br><span class="line">    D_output = D(G_output)</span><br><span class="line">    </span><br><span class="line">    G_loss = criterion(D_output, y)</span><br><span class="line">    G_loss.backward()</span><br><span class="line">    </span><br><span class="line">    G_optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> G_loss.data.item()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">D_train</span><span class="params">(x)</span>:</span></span><br><span class="line">    D.zero_grad()</span><br><span class="line">    <span class="comment"># x原来的shape [batch_size,3,28,28]</span></span><br><span class="line">    <span class="comment"># 3个通道都是一样的，取一个通道就行</span></span><br><span class="line">    x = x[:,<span class="number">0</span>,:,:]</span><br><span class="line">    x_real, y_real = x.view(<span class="number">-1</span>, mnist_dim), torch.ones(batch_size, <span class="number">1</span>)</span><br><span class="line">    x_real, y_real = Variable(x_real.to(device)), Variable(y_real.to(device))</span><br><span class="line">    </span><br><span class="line">    D_output = D(x_real)</span><br><span class="line">    D_real_loss = criterion(D_output, y_real)</span><br><span class="line">    <span class="comment">#D_real_score = D_output</span></span><br><span class="line">    </span><br><span class="line">    z = Variable(torch.randn(batch_size, z_dim).to(device))</span><br><span class="line">    x_fake, y_fake = G(z), Variable(torch.zeros(batch_size, <span class="number">1</span>).to(device))</span><br><span class="line"></span><br><span class="line">    D_output = D(x_fake)</span><br><span class="line">    D_fake_loss = criterion(D_output, y_fake)</span><br><span class="line">    <span class="comment">#D_fake_score = D_output</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># gradient backprop &amp; optimize ONLY D's parameters</span></span><br><span class="line">    D_loss = D_real_loss + D_fake_loss</span><br><span class="line">    D_loss.backward()</span><br><span class="line">    D_optimizer.step()</span><br><span class="line">   </span><br><span class="line">    <span class="keyword">return</span>  D_loss.data.item()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">n_epoch = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoch):</span><br><span class="line">    D_losses, G_losses = [], []</span><br><span class="line">    <span class="keyword">for</span> index,(x,_) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        D_losses.append(D_train(x))</span><br><span class="line">        G_losses.append(G_train(x))</span><br><span class="line">    print(<span class="string">'[%d/%d]: loss_d: %.3f, loss_g: %.3f'</span> % (</span><br><span class="line">            (epoch), n_epoch, torch.mean(torch.FloatTensor(D_losses)), torch.mean(torch.FloatTensor(G_losses))))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用训练好的GAN生成图片</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    test_z = Variable(torch.randn(batch_size, z_dim).to(device))</span><br><span class="line">    generated = G(test_z)</span><br><span class="line">    save_image(generated.view(generated.size(<span class="number">0</span>), <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), <span class="string">'./samples/sample_'</span> + <span class="string">'.png'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="2-各式各样的GAN"><a href="#2-各式各样的GAN" class="headerlink" title="2. 各式各样的GAN"></a>2. 各式各样的GAN</h3><h4 id="2-1DCGAN"><a href="#2-1DCGAN" class="headerlink" title="2.1DCGAN"></a>2.1DCGAN</h4><p>​        深度卷积生成对抗网络，在生成器中，对输入的一维向量不断进行转置卷积（上采样）最终生成对应的图像。在判别器中，则将输入的图像经过多层卷积最后经过sigmod函数进行二分类，判断这是原始数据图片还是生成器产生的图片。</p>
<p><img src="/images/dcgan.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weights_init</span><span class="params">(m)</span>:</span></span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    <span class="keyword">if</span> classname.find(<span class="string">'Conv'</span>) != <span class="number">-1</span>:</span><br><span class="line">        m.weight.data.normal_(<span class="number">0.0</span>, <span class="number">0.02</span>)</span><br><span class="line">    <span class="keyword">elif</span> classname.find(<span class="string">'BatchNorm'</span>) != <span class="number">-1</span>:</span><br><span class="line">        m.weight.data.normal_(<span class="number">1.0</span>, <span class="number">0.02</span>)</span><br><span class="line">        m.bias.data.fill_(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    input (N, in_dim)</span></span><br><span class="line"><span class="string">    output (N, 3, 64, 64)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_dim, dim=<span class="number">64</span>)</span>:</span></span><br><span class="line">        super(Generator, self).__init__()</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">dconv_bn_relu</span><span class="params">(in_dim, out_dim)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.ConvTranspose2d(in_dim, out_dim, <span class="number">5</span>, <span class="number">2</span>,</span><br><span class="line">                                   padding=<span class="number">2</span>, output_padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">                nn.BatchNorm2d(out_dim),</span><br><span class="line">                nn.ReLU())</span><br><span class="line">        self.l1 = nn.Sequential(</span><br><span class="line">            nn.Linear(in_dim, dim * <span class="number">8</span> * <span class="number">4</span> * <span class="number">4</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm1d(dim * <span class="number">8</span> * <span class="number">4</span> * <span class="number">4</span>),</span><br><span class="line">            nn.ReLU())</span><br><span class="line">        self.l2_5 = nn.Sequential(</span><br><span class="line">            dconv_bn_relu(dim * <span class="number">8</span>, dim * <span class="number">4</span>),</span><br><span class="line">            dconv_bn_relu(dim * <span class="number">4</span>, dim * <span class="number">2</span>),</span><br><span class="line">            dconv_bn_relu(dim * <span class="number">2</span>, dim),</span><br><span class="line">            nn.ConvTranspose2d(dim, <span class="number">3</span>, <span class="number">5</span>, <span class="number">2</span>, padding=<span class="number">2</span>, output_padding=<span class="number">1</span>),</span><br><span class="line">            nn.Tanh())</span><br><span class="line">        self.apply(weights_init)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y = self.l1(x)</span><br><span class="line">        y = y.view(y.size(<span class="number">0</span>), <span class="number">-1</span>, <span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">        y = self.l2_5(y)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    input (N, 3, 64, 64)</span></span><br><span class="line"><span class="string">    output (N, )</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, in_dim, dim=<span class="number">64</span>)</span>:</span></span><br><span class="line">        super(Discriminator, self).__init__()</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">conv_bn_lrelu</span><span class="params">(in_dim, out_dim)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_dim, out_dim, <span class="number">5</span>, <span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">                nn.BatchNorm2d(out_dim),</span><br><span class="line">                nn.LeakyReLU(<span class="number">0.2</span>))</span><br><span class="line">        self.ls = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_dim, dim, <span class="number">5</span>, <span class="number">2</span>, <span class="number">2</span>), nn.LeakyReLU(<span class="number">0.2</span>),</span><br><span class="line">            conv_bn_lrelu(dim, dim * <span class="number">2</span>),</span><br><span class="line">            conv_bn_lrelu(dim * <span class="number">2</span>, dim * <span class="number">4</span>),</span><br><span class="line">            conv_bn_lrelu(dim * <span class="number">4</span>, dim * <span class="number">8</span>),</span><br><span class="line">            nn.Conv2d(dim * <span class="number">8</span>, <span class="number">1</span>, <span class="number">4</span>),</span><br><span class="line">            nn.Sigmoid())</span><br><span class="line">        self.apply(weights_init)        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y = self.ls(x)</span><br><span class="line">        y = y.view(<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<h4 id="2-2-Conditional-GAN"><a href="#2-2-Conditional-GAN" class="headerlink" title="2.2 Conditional GAN"></a>2.2 Conditional GAN</h4><p>CGAN的目标函数与原始的并无太大不同，只不过加了一个限定条件。</p>
<script type="math/tex; mode=display">
\min_G \max_D V(D,G) = E_{x-p_{data}}[\log(D(x|y))] + E_{z-p_z}[\log[1 - D(G(z|y))]]</script><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># G(z)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Generator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># initializers</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(generator, self).__init__()</span><br><span class="line">        self.fc1_1 = nn.Linear(<span class="number">100</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc1_1_bn = nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line">        <span class="comment"># 处理label one-hot向量的</span></span><br><span class="line">        self.fc1_2 = nn.Linear(<span class="number">10</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc1_2_bn = nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line">        </span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">512</span>, <span class="number">512</span>)</span><br><span class="line">        self.fc2_bn = nn.BatchNorm1d(<span class="number">512</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">512</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc3_bn = nn.BatchNorm1d(<span class="number">1024</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">1024</span>, <span class="number">784</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># weight_init</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_init</span><span class="params">(self, mean, std)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self._modules:</span><br><span class="line">            normal_init(self._modules[m], mean, std)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, label)</span>:</span></span><br><span class="line">        x = F.relu(self.fc1_1_bn(self.fc1_1(input)))</span><br><span class="line">        y = F.relu(self.fc1_2_bn(self.fc1_2(label)))</span><br><span class="line">        <span class="comment"># 把两个向量进行合并</span></span><br><span class="line">        x = torch.cat([x, y], <span class="number">1</span>)</span><br><span class="line">        x = F.relu(self.fc2_bn(self.fc2(x)))</span><br><span class="line">        x = F.relu(self.fc3_bn(self.fc3(x)))</span><br><span class="line">        x = F.tanh(self.fc4(x))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Discriminator</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="comment"># initializers</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(discriminator, self).__init__()</span><br><span class="line">        self.fc1_1 = nn.Linear(<span class="number">784</span>, <span class="number">1024</span>)</span><br><span class="line">        <span class="comment"># 处理label one-hot向量 batch_size * 10</span></span><br><span class="line">        self.fc1_2 = nn.Linear(<span class="number">10</span>, <span class="number">1024</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">2048</span>, <span class="number">512</span>)</span><br><span class="line">        self.fc2_bn = nn.BatchNorm1d(<span class="number">512</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">512</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc3_bn = nn.BatchNorm1d(<span class="number">256</span>)</span><br><span class="line">        self.fc4 = nn.Linear(<span class="number">256</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># weight_init</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">weight_init</span><span class="params">(self, mean, std)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self._modules:</span><br><span class="line">            normal_init(self._modules[m], mean, std)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># forward method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, input, label)</span>:</span></span><br><span class="line">        x = F.leaky_relu(self.fc1_1(input), <span class="number">0.2</span>)</span><br><span class="line">        y = F.leaky_relu(self.fc1_2(label), <span class="number">0.2</span>)</span><br><span class="line">        </span><br><span class="line">        x = torch.cat([x, y], <span class="number">1</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc2_bn(self.fc2(x)), <span class="number">0.2</span>)</span><br><span class="line">        x = F.leaky_relu(self.fc3_bn(self.fc3(x)), <span class="number">0.2</span>)</span><br><span class="line">        x = F.sigmoid(self.fc4(x))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normal_init</span><span class="params">(m, mean, std)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(m, nn.Linear):</span><br><span class="line">        m.weight.data.normal_(mean, std)</span><br><span class="line">        m.bias.data.zero_()</span><br></pre></td></tr></table></figure>
<p>结合介绍的两种，可以定义<code>cDCNGAN</code>模型（就是把Linear全连接层换为了ConvTranspose2d或Conv2d卷积层）。</p>
<h4 id="2-3-Bidirectional-GAN"><a href="#2-3-Bidirectional-GAN" class="headerlink" title="2.3 Bidirectional GAN"></a>2.3 Bidirectional GAN</h4><p>讲述$BiGAN$的两篇论文分别为：</p>
<p>Donahue, Jeff, Philipp Krähenbühl, and Trevor Darrell. “Adversarial feature learning.” <em>arXiv preprint arXiv:1605.09782</em> (2016).</p>
<p>Dumoulin, Vincent, et al. “Adversarially learned inference.” <em>arXiv preprint arXiv:1606.00704</em> (2016).</p>
<ul>
<li><p>网络架构</p>
<p><img src="/images/bigan.png" alt="image-20200625104051977"></p>
</li>
</ul>
<ul>
<li>目标函数<script type="math/tex; mode=display">
\min_{G,E}\max_D V(D,E,G)</script><img src="/images/image-20200625104357166.png" alt="image-20200625104357166"></li>
</ul>
<p>代码参考：<a href="https://github.com/fmu2/Wasserstein-BiGAN" target="_blank" rel="noopener">https://github.com/fmu2/Wasserstein-BiGAN</a></p>
<h4 id="2-4-WGAN"><a href="#2-4-WGAN" class="headerlink" title="2.4 WGAN"></a>2.4 WGAN</h4><p>Arjovsky, M., Chintala, S., &amp; Bottou, L. (2017). Wasserstein gan. <em>arXiv preprint arXiv:1701.07875</em>.（gradient clipping）</p>
<p>Gulrajani, I., Ahmed, F., Arjovsky, M., Dumoulin, V., &amp; Courville, A. C. (2017). Improved training of wasserstein gans. In <em>Advances in neural information processing systems</em> (pp. 5767-5777).（gradient penalty）</p>
<p>​        参考：<a href="https://zhuanlan.zhihu.com/p/25071913（令人拍案叫绝的WGAN）。" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25071913（令人拍案叫绝的WGAN）。</a></p>
<p>​        $Wasserstein$距离也被称为$Earth  mover’s$距离（推土机距离）。<strong>Wasserstein距离相比KL散度、JS散度的优越性在于，即便两个分布没有重叠，Wasserstein距离仍然能够反映它们的远近。</strong></p>
<p>​        <strong>我们可以构造一个含参数$w$、最后一层不是非线性激活层的判别器网络$f_w$，在限制$w$不超过某个范围的条件下，使得</strong></p>
<script type="math/tex; mode=display">
L = E_{x-P_r}[f_w(x)] - E_{x-P_G}[f_w(x)]</script><p><strong>尽可能取到最大，此时$L$就会近似真实分布与生成分布之间的Wasserstein距离（忽略常数倍数$K$）。</strong></p>
<p><img src="https://pic1.zhimg.com/v2-6be6e2ef3d15c4b10c2a943e9bf4db70_r.jpg" alt=""></p>
<p><img src="/images/wgan-code.png" alt="image-20200622215347951"></p>
<p>注：判别器要迭代训练多次。而生成器只训练一次。</p>
<p><img src="/images/wgan-g.png" alt="image-20200622220223959"></p>
<p>WGAN在原生的GAN做出的改进：</p>
<ol>
<li>G和D的损失函数不用对数</li>
<li>不要用基于动量的优化算法（包括momentum和Adam），推荐RMSProp，SGD也行</li>
<li>D最后一层去掉$sigmod$二分类函数</li>
<li>采用gradient clipping和gradient penalty（改进）</li>
</ol>
<p>原始GAN存在的问题：</p>
<ul>
<li>判别器越好，生成器越容易产生梯度消失。</li>
<li>训练不稳定，容易导致$collapse mode$。</li>
</ul>
<h4 id="2-5-StackGAN由文本生成高分辨率图像"><a href="#2-5-StackGAN由文本生成高分辨率图像" class="headerlink" title="2.5 StackGAN由文本生成高分辨率图像"></a>2.5 StackGAN由文本生成高分辨率图像</h4><p>Zhang, Han, et al. “Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks.” <em>Proceedings of the IEEE international conference on computer vision</em>. 2017.</p>
<h4 id="2-6-GANomaly异常检测"><a href="#2-6-GANomaly异常检测" class="headerlink" title="2.6 GANomaly异常检测"></a>2.6 GANomaly异常检测</h4><ul>
<li>网络架构：</li>
</ul>
<p><img src="/images/ganomaly.png" alt="image-20200623103433011"></p>
<p>​        可以看出，模型包含两个encoder、一个decoder（相当于生成器）和一个判别器。模型划分为三个部分：第一部分为一个自动编码器，包含一个encoder（$G_E$）、一个decoder（$G_D$），这一部分被记为$G$；第二部分为一个encoder，记为$E$；第三部分为一个判别器网络，记为$D$。前两部分也被称为G-Net。</p>
<p>​        输入图片数据$x$经过一个encoder（$G_E$）编码为向量$z$，decoder（$G_D$）将向量$z$还原为原尺寸图像数据$\hat x$，另一个encoder（$E$）将$\hat x$又编码为向量$\hat z$。将$x$和$\hat x$输入判别器网络（$D$）判断图片是原始图片还是生成器生成的图片。</p>
<ul>
<li>损失函数</li>
</ul>
<p>​        损失函数共分为三部分，第一部分是$Enocder Loss$，衡量两个encoder编码向量的损失；第二部分是$Contextual Loss$，衡量原图像与生成器生成图像的损失，第三部分是$Adversial  Loss$，是常规的GAN中判别网络的损失，这里采用的是二分类的交叉熵损失。</p>
<p>​        优化D-net，采用$Adversial  Loss$。</p>
<p>​        优化G-net时，采用三部分损失函数的加权和。</p>
<ul>
<li>异常检测</li>
</ul>
<p>​        原理：由于训练输入的都是正常数据，第一个encoder学习到的是正常数据的分布，经过生成器的重建后再经过encoder编码差异不会很大，当输入异常数据时，encoder编码后会损失部分信息，经过生成器重建后再编码会与原来的数据差异很大，从而进行异常检测。</p>
<script type="math/tex; mode=display">
A(\hat x) = ||G_E(\hat x) - E(G(\hat x))||_1</script><p>​        当异常得分$A$大于某一阈值时，模型就会判定该数据为异常数据。（异常检测并没有用到判别器）。</p>
<h4 id="2-7-DiscoGAN关联分析"><a href="#2-7-DiscoGAN关联分析" class="headerlink" title="2.7 DiscoGAN关联分析"></a>2.7 DiscoGAN关联分析</h4><p><img src="/images/discogan.png" alt="image-20200623120348746"></p>
<p>​        模型主要由两个生成器和两个判别器构成。</p>
<ul>
<li><p>$G_{AB}$：输入A领域（domain）图片，生成B领域图片</p>
</li>
<li><p>$G_{BA}$：输入B领域图片，生成A领域图片</p>
</li>
<li><p>$D_A$：判别A领域原始图像和$G_{BA}$生成的A领域图像</p>
</li>
<li><p>$D_B$：判别B领域原始图像和$G_{AB}$生成的B领域图像</p>
</li>
</ul>
<p><img src="/images/disco-gan-loss.png" alt="image-20200623231830797"></p>
<p><img src="/images/disco-gan-loss2.png" alt="image-20200623231914928"></p>
<p><img src="/images/disco-gan-loss3.png" alt="image-20200623231950959"></p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-ZooKeeper基础教程" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/22/ZooKeeper%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/"
    >ZooKeeper基础教程</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/22/ZooKeeper%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B/" class="article-date">
  <time datetime="2020-06-22T03:09:01.189Z" itemprop="datePublished">2020-06-22</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="ZooKeeper基础教程"><a href="#ZooKeeper基础教程" class="headerlink" title="ZooKeeper基础教程"></a><code>ZooKeeper</code>基础教程</h2><h3 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h3><h4 id="1-1-简介"><a href="#1-1-简介" class="headerlink" title="1.1 简介"></a>1.1 简介</h4><p>​        <code>Zookeeper</code> 是一个基于Java的分布式协调服务的开源框架。主要用来解决分布式集群中应用系统的一致性问题，例如怎样避免同时操作同一数据造成脏读的问题。<code>ZooKeeper</code>本质上是一个分布式的<strong>小文件存储系统</strong>。提供基于类似于文件系统的目录树方式的数据存储，并且可以对树中的节点进行有效管理。从而用来维护和监控你存储的数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。诸如:统一命名服务、分布式配置管理、分布式消息队列、分布式锁、分布式协调等功能。</p>
<h4 id="1-2-集群"><a href="#1-2-集群" class="headerlink" title="1.2 集群"></a>1.2 集群</h4><p>​        <code>ZooKeeper</code>集群包含两种角色，Leader和Follower。</p>
<ul>
<li><p>Leader</p>
<p><code>Zookeeper</code>集群工作的核心，事务请求（写操作）的唯一调度和处理者，保证集群事务处理的顺序性；</p>
<p>集群内部各个服务器的调度者。 对于 <code>create，setData，delete</code> 等有写操作的请求，则需要统一转发给 leader处理，leader需要决定编号、执行操作，这个过程称为一个事务。</p>
</li>
<li><p>Follower</p>
<p>处理客户端非事务（读操作）请求，转发事务请求给 Leader； 参与集群 Leader 选举投票。 此外，针对访问量比较大的 <code>ZooKeeper</code> 集群，还可新增观察者角色。</p>
</li>
</ul>
<ul>
<li><p>Observer: </p>
<p>观察者角色，观察<code>Zookeeper</code> 集群的最新状态变化并将这些状态同步过 来，其对于非事务请求可以进行独立处理，对于事务请求，则会转发给Leader服务器进行处理。 </p>
<p>不会参与任何形式的投票只提供非事务服务，通常用于在不影响集群事务处理能力的前提下提升集群的非事务处理能力。</p>
</li>
</ul>
<h4 id="1-3-集群搭建"><a href="#1-3-集群搭建" class="headerlink" title="1.3 集群搭建"></a>1.3 集群搭建</h4><p>​        集群通常由<strong>2n+1</strong>台 servers 组成。这是因为为了保证 Leader 选举（基于<code>Paxos</code>算法的实现）能过得到多数的支持，所以<code>ZooKeeper</code>集群的数量一般为奇数。</p>
<p>​        <code>Zookeeper</code>运行需要<code>java</code>环境，所以需要提前安装 。对于安装 leader+follower 模式的集群，大致过程如下</p>
<ul>
<li><p>配置主机名称到IP地址映射配置</p>
</li>
<li><p>修改 <code>ZooKeeper</code> 配置文件（<code>/conf/zoo.cfg</code>文件）</p>
<p>配置data暂存目录，各个服务器地址ip</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">dataDir=/usr/local/zookeeper-3.4.14/zkData</span><br><span class="line"></span><br><span class="line">clientPort=2181</span><br><span class="line"></span><br><span class="line">server.0=192.168.10.1:2888:3888</span><br><span class="line">server.1=192.168.10.2:2888:3888</span><br><span class="line">server.2=192.168.10.3:2888:3888</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p><code>server.A=B:C:D</code>解释：</p>
<p>A：其中 A 是一个数字，表示这个是服务器的编号；</p>
<p>B：是这个服务器的IP地址；</p>
<p>C：<code>Leader</code>选举的端口；</p>
<p>D：<code>Zookeeper</code>服务器之间的通信端口。</p>
</li>
<li><p>远程复制分发安装文件</p>
</li>
<li><p>设置<code>myid</code></p>
<p>在 上一步<code>dataDir</code> 指定的目录下，创建<code>myid</code>文件。在对应的服务器上写入对应序号。</p>
<p>比如<code>192.168.10.1</code>对应<code>server.0</code>，那么在<code>myid</code>中写入0即可。</p>
</li>
<li><p>启动集群</p>
<p>启动命令：<code>zkServer.sh start</code></p>
<p>停止命令：<code>zkServer.sh stop</code></p>
<p>重启命令：<code>zkServer.sh restart</code></p>
<p>查看集群结点状态：<code>zkServer.sh status</code></p>
</li>
</ul>
<h3 id="2-Shell操作"><a href="#2-Shell操作" class="headerlink" title="2 Shell操作"></a>2 Shell操作</h3><p><code>bin/zkCli.sh</code>命令进入命令行界面。</p>
<h4 id="2-1-创建结点"><a href="#2-1-创建结点" class="headerlink" title="2.1 创建结点"></a>2.1 创建结点</h4><p><code>ZooKeeper</code>中的结点类型分为<strong>永久节点和临时结点(-e)</strong>。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create [-s] [-e] path data acl</span><br></pre></td></tr></table></figure>
<p>其中，-s 或-e 分别指定节点特性，顺序或临时节点，若不指定，则表示持 久节点；<code>acl</code>用来进行权限控制。</p>
<p>例子：</p>
<p>创建顺序节点，结点值为123：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create -s /test 123</span><br></pre></td></tr></table></figure>
<p>创建临时结点</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create -e /test-tmp 123</span><br></pre></td></tr></table></figure>
<p>创建永久节点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create /test-per 123p</span><br></pre></td></tr></table></figure>
<h4 id="2-2-读取节点"><a href="#2-2-读取节点" class="headerlink" title="2.2 读取节点"></a>2.2 读取节点</h4><pre><code>     与读取相关的命令有`ls`命令和 `get` 命令，`ls` 命令可以列出 `Zookeeper `指 定节点下的所有子节点，只能查看指定节点下的第一级的所有子节点；`get` 命令 可以获取 `Zookeeper` 指定节点的数据内容和属性信息。
</code></pre><p>查看根目录下所有结点：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[cluster, brokers, zookeeper, admin, isr_change_notification, log_dir_event_notification, node1, controller_epoch, servers, nefu, test0000000015, consumers, latest_producer_id_block, config]</span><br></pre></td></tr></table></figure>
<p>获取<code>/nefu</code>结点的信息</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 3] get /nefu</span><br><span class="line">ssss  #属性值</span><br><span class="line">cZxid = 0x12</span><br><span class="line">ctime = Thu Jun 04 16:51:44 CST 2020</span><br><span class="line">mZxid = 0x12</span><br><span class="line">mtime = Thu Jun 04 16:51:44 CST 2020</span><br><span class="line">pZxid = 0x12</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 0</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 4</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>
<h4 id="2-3-更新与删除结点"><a href="#2-3-更新与删除结点" class="headerlink" title="2.3 更新与删除结点"></a>2.3 更新与删除结点</h4><h5 id="2-3-1-更新结点"><a href="#2-3-1-更新结点" class="headerlink" title="2.3.1 更新结点"></a>2.3.1 更新结点</h5><p><code>set path data [version]</code> data 就是要更新的新内容，version 表示数据版本。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 5] set /nefu ilovenefu     </span><br><span class="line">cZxid = 0x12</span><br><span class="line">ctime = Thu Jun 04 16:51:44 CST 2020</span><br><span class="line">mZxid = 0xd7</span><br><span class="line">mtime = Mon Jun 22 11:37:18 CST 2020</span><br><span class="line">pZxid = 0x12</span><br><span class="line">cversion = 0</span><br><span class="line">dataVersion = 1 #注意这儿的版本号</span><br><span class="line">aclVersion = 0</span><br><span class="line">ephemeralOwner = 0x0</span><br><span class="line">dataLength = 9</span><br><span class="line">numChildren = 0</span><br></pre></td></tr></table></figure>
<h5 id="2-3-2-删除节点"><a href="#2-3-2-删除节点" class="headerlink" title="2.3.2 删除节点"></a>2.3.2 删除节点</h5><p><code>delete path [version]</code></p>
<p>注意：若删除节点存在子节点，那么无法删除该节点，必须先删除子节点，再删除父节点。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Rmr path</span><br></pre></td></tr></table></figure>
<h3 id="3-ZooKeeper数据模型"><a href="#3-ZooKeeper数据模型" class="headerlink" title="3. ZooKeeper数据模型"></a>3. <code>ZooKeeper</code>数据模型</h3><p>​        <code>ZooKeeper</code>的数据模型，在结构上和标准文件系统的非常相似，拥有一个层次的命名空间，都是采用树形层次结构，<code>ZooKeeper</code>树中的每个节点被称为一个<code>Znode</code>。和文件系统的目录树一样，<code>ZooKeeper</code>树中的每个节点可以拥有子节点。</p>
<p><img src="/images/zookeeper.png" alt=""></p>
<p>​        图中的每个节点称为一个<code>Znode</code> 。每个<code>Znode</code>由 3 部分组成:</p>
<p> ① stat：此为状态信息, 描述该 <code>Znode</code> 的版本, 权限等信息</p>
<p> ② data：与该 <code>Znode</code> 关联的数据 </p>
<p> ③ children：该<code>Znode</code>下的子节点</p>
<p>​        <code>Znode</code>有两种，分别为临时节点和永久节点。 </p>
<p>​        节点的类型在创建时即被确定，并且不能改变。 </p>
<p>​        <strong>临时节点</strong>：该节点的生命周期依赖于创建它们的会话。一旦<strong>会话结束</strong>，临时节点将被自动删除，当然可以也可以手动删除。临时节点不允许拥有子节点。 </p>
<p>​        <strong>永久节点</strong>：该节点的生命周期不依赖于会话，并且只有在客户端显示执行删 除操作的时候，他们才能被删除。 </p>
<p>​        <code>Znode</code>还有一个序列化的特性，如果创建的时候指定的话，该<code>Znode</code>的名字 后面会自动追加一个不断增加的序列号。序列号对于此节点的父节点来说是唯一 的，这样便会记录每个子节点创建的先后顺序。它的格式为“%10d”(10 位数字， 没有数值的数位用 0 补充，例如“0000000001”)。</p>
<h3 id="4-Watcher"><a href="#4-Watcher" class="headerlink" title="4. Watcher"></a>4. Watcher</h3><p>​        ZooKeeper 提供了分布式数据发布/订阅功能，一个典型的发布/订阅模型系统定义了一种一对多的订阅关系，能让多个订阅者同时监听某一个主题对象，当 这个主题对象自身状态变化时，会通知所有订阅者，使他们能够做出相应的处理。 </p>
<p>​        ZooKeeper 中，引入了 Watcher 机制来实现这种分布式的通知功能。 ZooKeeper 允许客户端向服务端注册一个 Watcher 监听，当服务端的一些事件触 发了这个 Watcher，那么就会向指定客户端发送一个事件通知来实现分布式的通知功能。</p>
<p>​         触发事件种类很多，如：节点创建，节点删除，节点改变，子节点改变等。 </p>
<p>​        总的来说可以概括 Watcher 为以下三个过程：客户端向服务端注册 Watcher、 服务端事件发生触发 Watcher、客户端回调 Watcher 得到触发事件情况。</p>
<h3 id="5-Java-API编程"><a href="#5-Java-API编程" class="headerlink" title="5. Java API编程"></a>5. Java API编程</h3><p>首先导入<code>pom</code>依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></span><br><span class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.nefu<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.zookeeper<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>zookeeper<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.10<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-core --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.8.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>简单的连接集群和结点操作</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.zookeeper.*;</span><br><span class="line"><span class="keyword">import</span> org.apache.zookeeper.data.Stat;</span><br><span class="line"><span class="keyword">import</span> org.junit.Before;</span><br><span class="line"><span class="keyword">import</span> org.junit.Test;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.List;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestZookeeper</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String connectionString = <span class="string">"139.129.100.28:2181"</span>;</span><br><span class="line">    <span class="keyword">private</span> ZooKeeper zkClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Before</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        zkClient = <span class="keyword">new</span> ZooKeeper(connectionString,<span class="number">2000</span>, <span class="keyword">new</span> Watcher() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">                List&lt;String&gt; children ;</span><br><span class="line">                <span class="keyword">try</span>&#123;</span><br><span class="line">                    System.out.println(<span class="string">"------------start----------------"</span>);</span><br><span class="line">                    children = zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line">                    System.out.println(children);</span><br><span class="line">                    System.out.println(<span class="string">"-------------end------------------"</span>);</span><br><span class="line">                &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCreateNode</span><span class="params">()</span> <span class="keyword">throws</span> KeeperException, InterruptedException </span>&#123;</span><br><span class="line">        String path = zkClient.create(<span class="string">"/nefu"</span>,<span class="string">"i wanna go back"</span>.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);</span><br><span class="line">        System.out.println(path);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">getChildren</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        zkClient.getChildren(<span class="string">"/"</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(Long.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exist</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span>&#123;</span><br><span class="line">        Stat stat = zkClient.exists(<span class="string">"/nefu"</span>, <span class="keyword">false</span>);</span><br><span class="line">        System.out.println(stat);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="6-ZooKeeper典型应用"><a href="#6-ZooKeeper典型应用" class="headerlink" title="6. ZooKeeper典型应用"></a>6. ZooKeeper典型应用</h3><h4 id="6-1-数据发布与订阅（配置中心）"><a href="#6-1-数据发布与订阅（配置中心）" class="headerlink" title="6.1 数据发布与订阅（配置中心）"></a>6.1 数据发布与订阅（配置中心）</h4><p>​        发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。</p>
<p>​         应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个 Watcher， 这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达 到获取最新配置信息的目的。</p>
<p>​        比如： 分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在 ZK 的一些指定节点，供各个客户端订阅使用。 </p>
<p>​        注意：适合数据量很小的场景，这样数据更新可能会比较快。</p>
<h4 id="6-2-命名服务-Naming-Service"><a href="#6-2-命名服务-Naming-Service" class="headerlink" title="6.2 命名服务(Naming Service)"></a>6.2 命名服务(Naming Service)</h4><p>​        在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取 资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提 供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其 中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用 ZK 提供的 创建节点的 API，能够很容易创建一个全局唯一的 path，这个 path 就可以作为 一个名称。</p>
<p>​        阿里巴巴集团开源的分布式服务框架 <code>Dubbo</code> 中使用 <code>ZooKeeper</code>来作为其命 名服务，维护全局的服务地址列表。</p>
<h4 id="6-3-分布式锁"><a href="#6-3-分布式锁" class="headerlink" title="6.3 分布式锁"></a>6.3 分布式锁</h4><p>​        分布式锁，这个主要得益于 ZooKeeper 保证了数据的强一致性。锁服务可以 分为两类，一个是保持独占，另一个是控制时序。</p>
<p>​        所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成 功获得这把锁。通常的做法是把 zk 上的一个 znode 看作是一把锁，通过 create znode 的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功 创建的那个客户端也即拥有了这把锁。</p>
<p>​        控制时序，就是所有试图来获取这个锁的客户端，最终都是会被安排执行， 只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经 预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制： CreateMode.EPHEMERAL_SEQUENTIAL 来指定）。Zk 的父节点（/distribute_lock） 维持一份 sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局 时序。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-LRU缓存机制" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/11/LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/"
    >LRU缓存机制</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/11/LRU%E7%BC%93%E5%AD%98%E6%9C%BA%E5%88%B6/" class="article-date">
  <time datetime="2020-06-10T16:17:54.353Z" itemprop="datePublished">2020-06-11</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Leetcode/">Leetcode</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="LRU缓存机制"><a href="#LRU缓存机制" class="headerlink" title="LRU缓存机制"></a>LRU缓存机制</h2><p>LRU即最近最久未使用。这是Leetcode 147号问题，主要采用了双向链表和哈希表这两种数据结构。双向链表相比单向链表，插入和删除的时间复杂度为O(1)，而哈希表在获取key的时间复杂度为O(1)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span> key, val;</span><br><span class="line">    <span class="keyword">public</span> Node prev, next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> val)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.val = val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 双向链表</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubleList</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Node head, tail;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> length = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DoubleList</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        head = <span class="keyword">new</span> Node(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">        tail = <span class="keyword">new</span> Node(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">        head.next = tail;</span><br><span class="line">        tail.prev = head;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addFirst</span><span class="params">(Node n)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 双向链表头部添加节点</span></span><br><span class="line">        n.next = head.next;</span><br><span class="line">        n.prev = head;</span><br><span class="line"></span><br><span class="line">        head.next.prev = n;</span><br><span class="line">        head.next = n;</span><br><span class="line">        length++;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(Node x)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 删除链表中的结点</span></span><br><span class="line">        x.prev.next = x.next;</span><br><span class="line">        x.next.prev = x.prev;</span><br><span class="line">        length--;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Node <span class="title">removeLast</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 首先判断链表是否为空</span></span><br><span class="line">        <span class="keyword">if</span> (head.next == tail) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        Node res = tail.prev;</span><br><span class="line">        remove(res);</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.length;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;Integer, Node&gt; map;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> DoubleList cache;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">        map = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        cache = <span class="keyword">new</span> DoubleList();</span><br><span class="line">        <span class="keyword">this</span>.capacity = capacity;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!map.containsKey(key)) &#123;</span><br><span class="line">            <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> val = map.get(key).val;</span><br><span class="line">        put(key, val);</span><br><span class="line">        <span class="keyword">return</span> val;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        Node x = <span class="keyword">new</span> Node(key, value);</span><br><span class="line">        <span class="keyword">if</span> (map.containsKey(key)) &#123;</span><br><span class="line">            <span class="comment">// map中存在key，更新值</span></span><br><span class="line">            cache.remove(map.get(key));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">this</span>.capacity == cache.size()) &#123;</span><br><span class="line">                <span class="comment">// 删除最久未使用的结点 -- 最后一个结点</span></span><br><span class="line">                Node last = cache.removeLast();</span><br><span class="line">                map.remove(last.key);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        cache.addFirst(x);</span><br><span class="line">        map.put(key, x);<span class="comment">// if else 中都有的逻辑，提取出来</span></span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-数据分析之Pandas" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/10/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas/"
    >数据分析之Pandas</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/10/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BPandas/" class="article-date">
  <time datetime="2020-06-09T16:22:30.243Z" itemprop="datePublished">2020-06-10</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="数据分析之Pandas"><a href="#数据分析之Pandas" class="headerlink" title="数据分析之Pandas"></a>数据分析之Pandas</h2><p>​    Pandas中两大数据结构：DataFrame、Series。</p>
<ol>
<li><p>数据文件的读取。可以读取excel、csv、tsv等数据文件。下面以csv文件为例</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'https://bitly.com/imdbratings'</span>)</span><br></pre></td></tr></table></figure>
<p>具体可以指定的参数有：</p>
<ul>
<li><p>encoding，文件编码方式，如：<code>GBK/ANSI/UTF-8</code></p>
</li>
<li><p>names，指定数据文件的各个列的名称，传入的是list类型</p>
</li>
<li><p>seq，指定文件的分隔符</p>
</li>
</ul>
</li>
<li><p>查看数据相关信息</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.head()</span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas-1.png" alt=""></p>
</li>
</ol>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">df.info()</span><br><span class="line">&lt;<span class="class"><span class="keyword">class</span> '<span class="title">pandas</span>.<span class="title">core</span>.<span class="title">frame</span>.<span class="title">DataFrame</span>'&gt;</span></span><br><span class="line"><span class="class"><span class="title">RangeIndex</span>:</span> <span class="number">979</span> entries, <span class="number">0</span> to <span class="number">978</span></span><br><span class="line">Data columns (total <span class="number">6</span> columns):</span><br><span class="line"> <span class="comment">#   Column          Non-Null Count  Dtype  </span></span><br><span class="line">---  ------          --------------  -----  </span><br><span class="line"> <span class="number">0</span>   star_rating     <span class="number">979</span> non-null    float64</span><br><span class="line"> <span class="number">1</span>   title           <span class="number">979</span> non-null    object </span><br><span class="line"> <span class="number">2</span>   content_rating  <span class="number">976</span> non-null    object </span><br><span class="line"> <span class="number">3</span>   genre           <span class="number">979</span> non-null    object </span><br><span class="line"> <span class="number">4</span>   duration        <span class="number">979</span> non-null    int64  </span><br><span class="line"> <span class="number">5</span>   actors_list     <span class="number">979</span> non-null    object </span><br><span class="line">dtypes: float64(<span class="number">1</span>), int64(<span class="number">1</span>), object(<span class="number">4</span>)</span><br><span class="line">memory usage: <span class="number">46.0</span>+ KB</span><br></pre></td></tr></table></figure>
   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df.describe()</span><br><span class="line">	  star_rating	duration</span><br><span class="line">count	<span class="number">979.000000</span>	<span class="number">979.000000</span></span><br><span class="line">mean	<span class="number">7.889785</span>	<span class="number">120.979571</span></span><br><span class="line">std		<span class="number">0.336069</span>	<span class="number">26.218010</span></span><br><span class="line">min		<span class="number">7.400000</span>	<span class="number">64.000000</span></span><br><span class="line"><span class="number">25</span>%		<span class="number">7.600000</span>	<span class="number">102.000000</span></span><br><span class="line"><span class="number">50</span>%		<span class="number">7.800000</span>	<span class="number">117.000000</span></span><br><span class="line"><span class="number">75</span>%		<span class="number">8.100000</span>	<span class="number">134.000000</span></span><br><span class="line">max		<span class="number">9.300000</span>	<span class="number">242.000000</span></span><br></pre></td></tr></table></figure>
<ol>
<li><p>获取某一列或多个列的值</p>
<p>通常将要获取的多个列名包装到list中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取评分这一列的值，返回一个Series对象</span></span><br><span class="line">df[<span class="string">'star_rating'</span>]</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">df.star_rating</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取评分、电影时长两列的值</span></span><br><span class="line">df[[<span class="string">'star_rating'</span>,<span class="string">'duration'</span>]]</span><br></pre></td></tr></table></figure>
<p>注意：不能这么写：<code>df[[0,1,2,3]]</code></p>
</li>
<li><p>获取某一行或多行的数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#直接切片获取 </span></span><br><span class="line">df[:<span class="number">1</span>]</span><br><span class="line"><span class="comment">#Output</span></span><br><span class="line">star_rating                                                     <span class="number">9.3</span></span><br><span class="line">title                                      The Shawshank Redemption</span><br><span class="line">content_rating                                                    R</span><br><span class="line">genre                                                         Crime</span><br><span class="line">duration                                                        <span class="number">142</span></span><br><span class="line">actors_list       [<span class="string">u'Tim Robbins'</span>, <span class="string">u'Morgan Freeman'</span>, <span class="string">u'Bob Gunt...</span></span><br><span class="line"><span class="string">Name: 0, dtype: object</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#获取前10部电影的时长</span></span><br><span class="line"><span class="string">df[:10]['</span>duration<span class="string">'] </span></span><br><span class="line"><span class="string">df[:10][['</span>star_rating<span class="string">','</span>duration<span class="string">']]</span></span><br></pre></td></tr></table></figure>
<p>还是推荐使用loc或者iloc来进行行的获取。这样更加直观。</p>
</li>
<li><p><strong>iloc和loc</strong></p>
<p>使用形式：<code>loc[,]/iloc[,]</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取指定索引的数据，比如获取第10部电影的数据</span></span><br><span class="line">df.loc[<span class="number">10</span>] <span class="comment"># 默认取全部列（不建议这么写） 相当于 ） </span></span><br><span class="line">df.loc[<span class="number">10</span>,:] <span class="comment">#（推荐）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 取第1、5、10部电影</span></span><br><span class="line">df.loc[[<span class="number">1</span>,<span class="number">5</span>,<span class="number">10</span>], :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># loc函数支持切片, 取前10部电影, 注意是：前闭后闭的</span></span><br><span class="line">df.loc[:<span class="number">10</span>,:] <span class="comment">#获取前10行的数据，返回一个DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面讲解列操作</span></span><br><span class="line"><span class="comment"># 取前10部电影的时长</span></span><br><span class="line">df.loc[:<span class="number">10</span>,<span class="string">'duration'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取前10部电影的时长和名字</span></span><br><span class="line">df.loc[:<span class="number">10</span>,[<span class="string">'star_rating'</span>,<span class="string">'title'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 取前10部电影评分到时长列</span></span><br><span class="line">df.loc[:<span class="number">10</span>,[<span class="string">'star_rating'</span>:<span class="string">'duration'</span>]]                   </span><br><span class="line">              </span><br><span class="line"><span class="comment"># 下面全部是错误的写法！</span></span><br><span class="line">df[:<span class="number">10</span>][<span class="string">'star_rating'</span>:<span class="string">'duration'</span>]   </span><br><span class="line">df.loc[:,<span class="number">0</span>:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><strong>注意：获取某一特定index行，不可以直接<code>df[index]</code>，需借助<code>df.loc[index,:]</code>函数。</strong></p>
<p>loc不仅可以传入索引、列表、切片获得指定数据，还可以传入条件进行筛选，具体参见下一小节。</p>
<p>iloc在列的选取上与loc不同，loc传入的是列名；而iloc传入的是列的索引。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#介绍df.iloc使用， iloc是按位置选取的,传入的参数都是整数</span></span><br><span class="line"><span class="comment"># 传入的切片是前闭后开的！</span></span><br><span class="line"><span class="comment">#选取索引为1、4、5的电影</span></span><br><span class="line">df.iloc[[<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>],:]</span><br><span class="line"></span><br><span class="line">df.iloc[:<span class="number">100</span>,:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择第0、2列</span></span><br><span class="line">df.iloc[[<span class="number">1</span>,<span class="number">4</span>,<span class="number">5</span>],[<span class="number">0</span>,<span class="number">2</span>]]</span><br></pre></td></tr></table></figure>
</li>
<li><p>获取满足特定条件的行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取电影时长在120min以上的电影，返回一个DataFrame</span></span><br><span class="line">df[df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>]</span><br><span class="line">df[df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>].duration</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取电影时长在120min以上的电影且评分高于8的电影,多条件要用括号括起来</span></span><br><span class="line">df[(df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>) &amp; (df[<span class="string">'star_rating'</span>] &gt; <span class="number">8</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line">df.loc[(df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>) &amp; (df[<span class="string">'star_rating'</span>] &gt; <span class="number">8</span>), :]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取电影时长在120min以上的电影且评分高于8的电影的名字</span></span><br><span class="line">df.loc[(df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>) &amp; (df[<span class="string">'star_rating'</span>] &gt; <span class="number">8</span>),<span class="string">'title'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取电影时长在120min以上的电影且评分高于8的电影的名字和评分</span></span><br><span class="line">df.loc[(df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>) &amp; (df[<span class="string">'star_rating'</span>] &gt; <span class="number">8</span>),[<span class="string">'title'</span>,<span class="string">'star_rating'</span>]]</span><br><span class="line"></span><br><span class="line">df.loc[(df[<span class="string">'duration'</span>] &gt; <span class="number">120</span>) &amp; (df[<span class="string">'star_rating'</span>] &gt; <span class="number">8</span>),<span class="string">'star_rating'</span>:<span class="string">'genre'</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看不同分级的电影数量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取电影具体的分级级别</span></span><br><span class="line">df[<span class="string">'content_rating'</span>].unique()</span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line">array([<span class="string">'R'</span>, <span class="string">'PG-13'</span>, <span class="string">'NOT RATED'</span>, <span class="string">'PG'</span>, <span class="string">'UNRATED'</span>, <span class="string">'APPROVED'</span>, <span class="string">'PASSED'</span>,</span><br><span class="line">       <span class="string">'G'</span>, <span class="string">'X'</span>, nan, <span class="string">'TV-MA'</span>, <span class="string">'GP'</span>, <span class="string">'NC-17'</span>], dtype=object)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看不同分级类别的电影数量</span></span><br><span class="line">df[<span class="string">'content_rating'</span>].value_counts()</span><br><span class="line"><span class="comment"># Output</span></span><br><span class="line">R            <span class="number">460</span></span><br><span class="line">PG<span class="number">-13</span>        <span class="number">189</span></span><br><span class="line">PG           <span class="number">123</span></span><br><span class="line">NOT RATED     <span class="number">65</span></span><br><span class="line">APPROVED      <span class="number">47</span></span><br><span class="line">UNRATED       <span class="number">38</span></span><br><span class="line">G             <span class="number">32</span></span><br><span class="line">PASSED         <span class="number">7</span></span><br><span class="line">NC<span class="number">-17</span>          <span class="number">7</span></span><br><span class="line">X              <span class="number">4</span></span><br><span class="line">GP             <span class="number">3</span></span><br><span class="line">TV-MA          <span class="number">1</span></span><br><span class="line">Name: content_rating, dtype: int64</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 以柱状图形式展示</span></span><br><span class="line">df[<span class="string">'content_rating'</span>].value_counts().plot(kind=<span class="string">'bar'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/images/content-rating.png" alt=""></p>
</li>
<li><p>groupby的应用</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看不同题材的电影的平均时长</span></span><br><span class="line">df.groupby(<span class="string">'genre'</span>).duration.mean()</span><br></pre></td></tr></table></figure>
</li>
<li><p>apply、map、applymap</p>
<p>apply传入一个函数，会将该函数应用于选中的列</p>
<p>applymap是指将函数应用于DataFrame的所有元素</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">df[<span class="string">'int_rating'</span>] = df.star_rating.apply(np.ceil) <span class="comment"># 默认为 0</span></span><br><span class="line">df.loc[:<span class="number">5</span>,[<span class="string">'int_rating'</span>,<span class="string">'star_rating'</span>]]</span><br><span class="line"></span><br><span class="line"><span class="comment">#Output</span></span><br><span class="line">	int_rating	star_rating</span><br><span class="line"><span class="number">0</span>			<span class="number">10.0</span> 		<span class="number">9.3</span></span><br><span class="line"><span class="number">1</span>			<span class="number">10.0</span>		<span class="number">9.2</span></span><br><span class="line"><span class="number">2</span>			<span class="number">10.0</span>		<span class="number">9.1</span></span><br><span class="line"><span class="number">3</span>			<span class="number">9.0</span>			<span class="number">9.0</span></span><br><span class="line"><span class="number">4</span>			<span class="number">9.0</span>			<span class="number">8.9</span></span><br><span class="line"><span class="number">5</span>			<span class="number">9.0</span>			<span class="number">8.9</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取电影主演的第一个演员的名字</span></span><br><span class="line">df.actors_list.apply(<span class="keyword">lambda</span> x:eval(x)[<span class="number">0</span>])</span><br><span class="line"><span class="comment">#Outputs</span></span><br><span class="line"><span class="number">0</span>          Tim Robbins</span><br><span class="line"><span class="number">1</span>        Marlon Brando</span><br><span class="line"><span class="number">2</span>            Al Pacino</span><br><span class="line"><span class="number">3</span>       Christian Bale</span><br><span class="line"><span class="number">4</span>        John Travolta</span><br></pre></td></tr></table></figure>
<p>下面引入一个新的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drinks = pd.read_csv(<span class="string">'http://bit.ly/drinksbycountry'</span>)</span><br><span class="line">drinks.head()</span><br></pre></td></tr></table></figure>
<p><img src="/images/pandas-2.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在DataFrame中，可通过axis指定appply作用在行或者列上</span></span><br><span class="line">res = drinks.loc[:,<span class="string">'beer_servings'</span>:<span class="string">'wine_servings'</span>].apply(np.argmax,axis=<span class="number">0</span>)</span><br><span class="line">res</span><br><span class="line"><span class="comment"># Outputs</span></span><br><span class="line">beer_servings      <span class="number">117</span></span><br><span class="line">spirit_servings     <span class="number">68</span></span><br><span class="line">wine_servings       <span class="number">61</span></span><br><span class="line">dtype: int64</span><br><span class="line">    </span><br><span class="line">drinks.loc[res,<span class="string">'country'</span>]</span><br><span class="line"><span class="number">117</span>    Namibia</span><br><span class="line"><span class="number">68</span>     Grenada</span><br><span class="line"><span class="number">61</span>      France</span><br><span class="line"><span class="comment"># 即beer_servings 最大的国家是Namibia，spirit_servings大的国家Grenada等等</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>在DataFrame中删除行或者列</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除一列或多列</span></span><br><span class="line">df.drop([<span class="string">'int_rating'</span>],axis=<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除一行或多行</span></span><br><span class="line">df.drop([<span class="number">0</span>,<span class="number">1</span>], axis = <span class="number">0</span>, inplace = <span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<ol>
<li><p>在DataFrame中给某一列重命名</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取所有列名</span></span><br><span class="line">df.columns</span><br><span class="line"><span class="comment"># 替换全部列名</span></span><br><span class="line">df_cols = [<span class="string">'Star rating'</span>,<span class="string">'Title'</span>, <span class="string">'Content rating'</span>,<span class="string">'Genre'</span>, <span class="string">'Duration'</span>, <span class="string">'Actors list'</span>]</span><br><span class="line">df.columns = df_cols</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改指定列名</span></span><br><span class="line">df.rename(columns = &#123;<span class="string">'star_rating'</span>:<span class="string">'star rating'</span>&#125;)</span><br></pre></td></tr></table></figure>
<p>也可以通过在read数据时，指定names参数来指定列名（<code>names = df_cols</code>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 也可以.str来使用Series中封装的字符串方法</span></span><br><span class="line">df.columns.str.[replace(<span class="string">'_'</span>,<span class="string">' '</span>)/lower()/upper()]</span><br></pre></td></tr></table></figure>
</li>
<li><p>给某一列进行排序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pandas.Series.sort_values(ascending=True, inplace=False) 默认升序,且不改变原Series结果</span></span><br><span class="line"><span class="comment"># 按照电影时长从大倒小排序</span></span><br><span class="line">df.duration.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas.DataFrame.sort_values(by='columns_name')</span></span><br><span class="line">df.sort_values(by=<span class="string">'duration'</span>,ascending=<span class="literal">False</span>,inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照电影评分从大到小排列，若评分相同，则时长长的在前</span></span><br><span class="line">df.sort_values([<span class="string">'star_rating'</span>,<span class="string">'duration'</span>],ascending=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>发现并删除重复行</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pandas.Series.duplicated() 返回bool的series</span></span><br><span class="line">df.title.duplicated().sum()</span><br><span class="line"></span><br><span class="line">df.duplicated()</span><br><span class="line"></span><br><span class="line">df.drop_duplicates(keep=<span class="string">'first'</span>)</span><br><span class="line"><span class="comment"># keep = first即保存第一个重复的元素，keep = False，不保留重复元素</span></span><br></pre></td></tr></table></figure>
</li>
</ol>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-Java中多态和方法的重载和重写" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/06/Java%E4%B8%AD%E5%A4%9A%E6%80%81%E5%92%8C%E6%96%B9%E6%B3%95%E7%9A%84%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99/"
    >Java中多态和方法的重载和重写</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/06/Java%E4%B8%AD%E5%A4%9A%E6%80%81%E5%92%8C%E6%96%B9%E6%B3%95%E7%9A%84%E9%87%8D%E8%BD%BD%E5%92%8C%E9%87%8D%E5%86%99/" class="article-date">
  <time datetime="2020-06-06T02:45:23.060Z" itemprop="datePublished">2020-06-06</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Java/">Java</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="Java中多态和方法的重载和重写"><a href="#Java中多态和方法的重载和重写" class="headerlink" title="Java中多态和方法的重载和重写"></a>Java中多态和方法的重载和重写</h2><p>重载（Overload）：指在同一个类中，方法名相同，而<strong>参数列表</strong>不同，参数列表指参数的<strong>顺序、类型、个数</strong>。重载与方法的返回类型、可见类型无关（例1）。</p>
<p>具体例子：</p>
<p><img src="/images/ex1.png" alt="例1"></p>
<p><img src="/images/ex1-1.png" alt="image-20200608221031279"></p>
<center>
    例1 重载与方法返回类型无关
</center>



<p>重写（Overwrite）：指的是在继承关系中，子类定义了与父类的同名方法且参数列表与父类方法完全一致。注意：子类的方法名、参数列表必须与父类（接口）定义的完全一致，否则不能称为覆写（例7）；确认重写关系后，当返回类型为基本类型时（<code>int、double、char、short、byte、float、bool、long、String</code>）子类覆写时<strong>不可以改变</strong>返回类型，当返回类型为引用型，子类返回的引用型只能为，父类返回类型的子类或相同类型，不可以为无关的引用类型。覆写不可以缩小父类方法的可见性！（例5）。</p>
<p>总结起来就是，首先确认子类方法名和参数列表是否与父方法<strong>完全一致</strong>，如果是，那么就是重写，语法要求方法返回类型务必和父类方法相同，且不可以减小该方法可见性；如果不是，则不是重写。</p>
<p>具体例子</p>
<p><img src="/images/ex2.png" alt="例2-1"></p>
<p><img src="/images/ex2-2.png" alt="例2-2"></p>
 <center> 
     例2 重写时，返回类型务必相同<center>
 </center>



<p><img src="/images/ex3.png" alt="image-20200608221852911"></p>
<center>
    例3 重写时，子类返回类型为父类方法返回类型的子类或实现类，参数列务必表完全相同
</center>



<p><img src="/images/ex4.png" alt="image-20200608221930946"></p>
<center>
    例4 重写时，子类返回类型不允许为与父类方法返回类型毫无关系的类型
</center>



<p><img src="/images/ex5.png" alt="image-20200608222225893"></p>
<center>
    例5 重写时，子类不允许减小父方法可见性
</center>



<p><img src="/images/ex6.png" alt="image-20200608223224765"></p>
<center>
    例6 重写时，子类重写的方法返回类型不能为
</center>



<p><img src="/images/ex7-1.png" alt="image-20200608223631425"></p>
<p><img src="/images/ex7-2.png" alt="image-20200608223608764"></p>
<center>
    例7 当参数列表不同时，这两个方法不存在覆写关系，加上注解就会报错
</center>

<p>顺便提一下，多态指的是动态绑定方法，而非类内变量。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Father</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> i + <span class="number">10</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Son</span> <span class="keyword">extends</span> <span class="title">Father</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Father son = <span class="keyword">new</span> Son();</span><br><span class="line">		System.out.println(son.test()); <span class="comment">// 10 子类没有定义test，找到父类方法，由于多态不动态绑定变量，因此i取得是父类的</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Father</span> </span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> getI() + <span class="number">10</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> i;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Son</span> <span class="keyword">extends</span> <span class="title">Father</span></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> i = <span class="number">10</span>;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> i;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Father son = <span class="keyword">new</span> Son();</span><br><span class="line">		Son son2 = <span class="keyword">new</span> Son();</span><br><span class="line">		</span><br><span class="line">		System.out.println(son.test()); <span class="comment">// 20</span></span><br><span class="line">		System.out.println(son2.test());<span class="comment">// 20</span></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-归一化和标准化" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/05/23/%E5%BD%92%E4%B8%80%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96/"
    >归一化和标准化</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/23/%E5%BD%92%E4%B8%80%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96/" class="article-date">
  <time datetime="2020-05-23T12:29:05.107Z" itemprop="datePublished">2020-05-23</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="归一化和标准化"><a href="#归一化和标准化" class="headerlink" title="归一化和标准化"></a>归一化和标准化</h2><p>​        注：本文内容转载自:<a href="https://www.jianshu.com/p/4c3081d40ca6" target="_blank" rel="noopener">https://www.jianshu.com/p/4c3081d40ca6</a></p>
<h2 id="1-先说是什么，再说为什么"><a href="#1-先说是什么，再说为什么" class="headerlink" title="1. 先说是什么，再说为什么"></a>1. 先说是什么，再说为什么</h2><ul>
<li><p>归一化：</p>
<p>就是将训练集中某一列<strong>数值</strong>特征（假设是第i列）的值缩放到<strong>0和1</strong>之间。方法如下所示：</p>
<script type="math/tex; mode=display">
\frac{x_i - \min(x)}{\max(x) - \min(x)}</script></li>
<li><p>标准化：</p>
<p>就是将训练集中某一列<strong>数值</strong>特征（假设是第i列）的值缩放成<strong>均值为0，方差为1</strong>的状态。如下所示：</p>
<script type="math/tex; mode=display">
\frac{x_i - \bar{x}}{std(x)}</script></li>
</ul>
<p>  sklearn中<code>MinmaxScaler</code>对应着归一化，<code>StandardScaler</code>对应标准化。</p>
<p>  神经网络中Batch Normalization对应标准化，即把样本拉回到均值为0，方差为1的分布上。</p>
<ul>
<li><p>进一步明确二者含义：</p>
<p>归一化和标准化的相同点都是对<strong>某个特征（column）</strong>进行缩放（scaling）而不是对某个样本的特征向量（row）进行缩放。对特征向量进行缩放是毫无意义的（<strong>暗坑1</strong>），比如三列特征：身高、体重、血压。每一条样本（row）就是三个这样的值，对这个row无论是进行标准化还是归一化都是好笑的，因为你不能将身高、体重和血压混到一起去！<br> 在线性代数中，将一个向量除以向量的长度，也被称为标准化，不过这里的标准化是将向量变为长度为1的单位向量，它和我们这里的标准化不是一回事儿，不要搞混哦（<strong>暗坑2</strong>）。</p>
</li>
</ul>
<h2 id="2-标准化和归一化的对比分析"><a href="#2-标准化和归一化的对比分析" class="headerlink" title="2. 标准化和归一化的对比分析"></a>2. 标准化和归一化的对比分析</h2><p>首先明确，在机器学习中，标准化是更常用的手段，归一化的应用场景是有限的。我总结原因有两点：</p>
<ul>
<li>1、标准化更好保持了样本间距。当样本中有异常点时，归一化有可能将正常的样本“挤”到一起去。比如三个样本，某个特征的值为1,2,10000，假设10000这个值是异常值，用归一化的方法后，正常的1,2就会被“挤”到一起去。如果不幸的是1和2的分类标签还是相反的，那么，当我们用梯度下降来做分类模型训练时，模型会需要更长的时间收敛，因为将样本分开需要更大的努力！而标准化在这方面就做得很好，至少它不会将样本“挤到一起”。</li>
<li>2、标准化更符合统计学假设<br> 对一个数值特征来说，很大可能它是服从正态分布的。标准化其实是基于这个隐含假设，只不过是略施小技，将这个正态分布调整为均值为0，方差为1的标准正态分布而已。</li>
</ul>
<h2 id="3-逻辑回归是否需要标准化"><a href="#3-逻辑回归是否需要标准化" class="headerlink" title="3. 逻辑回归是否需要标准化"></a>3. 逻辑回归是否需要标准化</h2><p>真正的答案是，这取决于我们的逻辑回归是不是用正则。</p>
<p><strong>如果你不用正则，那么，标准化并不是必须的，如果你用正则，那么标准化是必须的。（暗坑3）</strong></p>
<p>因为不用正则时，我们的损失函数<strong>只是仅仅</strong>在度量<strong>预测与真实的差距</strong>，加上正则后，我们的损失函数除了要度量上面的差距外，还要度量<strong>参数值</strong>是否足够小。而<strong>参数值的大小程度或者说大小的级别是与特征的数值范围</strong>相关的。举例来说，我们用体重预测身高，体重用kg衡量时，训练出的模型是：<br>身高 = 体重*x，x就是我们训练出来的参数。</p>
<p>当我们的体重用吨来衡量时，x的值就会扩大为原来的1000倍。<br>在上面两种情况下，都用L1正则的话，显然对模型的训练影响是不同的。</p>
<p>假如不同的特征的数值范围不一样，有的是0到0.1，有的是100到10000，那么，每个特征对应的参数大小级别也会不一样，在L1正则时，我们是简单将参数的绝对值相加，因为它们的大小级别不一样，就会导致L1最后只会对那些级别比较大的参数有作用，那些小的参数都被忽略了。</p>
<p>如果你回答到这里，面试官应该基本满意了，但是他可能会进一步考察你，如果不用正则，那么标准化对逻辑回归有什么好处吗？</p>
<p>答案是有好处，进行标准化后，我们得出的参数值的大小可以反应出不同特征对样本label的<strong>贡献度</strong>，方便我们进行特征筛选。如果不做标准化，是不能这样来筛选特征的。</p>
<p>答到这里，有些厉害的面试官可能会继续问，做标准化有什么注意事项吗？</p>
<p><strong>最大的注意事项就是先拆分出test集，不要在整个数据集上做标准化，因为那样会将test集的信息引入到训练集中，这是一个非常容易犯的错误！</strong></p>
<h2 id="4-决策树需要标准化吗"><a href="#4-决策树需要标准化吗" class="headerlink" title="4. 决策树需要标准化吗"></a>4. 决策树需要标准化吗</h2><p>答案是不需要标准化。因为决策树中的切分依据，信息增益、信息增益比、Gini指数都是基于概率得到的，和值的大小没有关系。另外同属概率模型的朴素贝叶斯，隐马尔科夫也不需要标准化。</p>
<h2 id="5-总结"><a href="#5-总结" class="headerlink" title="5. 总结"></a>5. 总结</h2><ol>
<li><p><strong>搞清楚标准化和归一化的具体定义和区别</strong></p>
</li>
<li><p><strong>标准化要在train_test_split后，在训练集、测试集上分别进行标准化</strong></p>
</li>
<li><p><strong>决策树、朴素贝叶斯等概率模型不需要标准化</strong></p>
</li>
</ol>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-Vuex使用" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/05/23/Vuex%E4%BD%BF%E7%94%A8/"
    >Vuex使用</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/23/Vuex%E4%BD%BF%E7%94%A8/" class="article-date">
  <time datetime="2020-05-23T09:17:03.636Z" itemprop="datePublished">2020-05-23</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/JS/">JS</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="Vuex使用"><a href="#Vuex使用" class="headerlink" title="Vuex使用"></a>Vuex使用</h2><p>​        <code>Vuex</code>是一个状态管理库，使用单一状态树管理应用内的全局状态。</p>
<p>​        <code>index.js</code>文件如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> Vue <span class="keyword">from</span> <span class="string">"vue"</span>;</span><br><span class="line"><span class="keyword">import</span> Vuex <span class="keyword">from</span> <span class="string">"vuex"</span>;</span><br><span class="line"><span class="keyword">import</span> cart <span class="keyword">from</span> <span class="string">"./cart"</span></span><br><span class="line">Vue.use(Vuex);</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> store = <span class="keyword">new</span> Vuex.Store(&#123;</span><br><span class="line">  <span class="comment">//全局的state</span></span><br><span class="line">  <span class="comment">// 如何调用：this.$store.state.状态名 / this.$store.state.模块名.状态名</span></span><br><span class="line">  state: &#123;</span><br><span class="line">    isTabbarShow: <span class="literal">true</span>,</span><br><span class="line">    itemList: [],</span><br><span class="line">  &#125;,</span><br><span class="line">  mutations: &#123;</span><br><span class="line">    <span class="comment">//修改state操作，state为第一个参数，vue会自动注入该函数</span></span><br><span class="line">    <span class="comment">//如何调用：this.$store.commit("函数名",[data])</span></span><br><span class="line">    HideTabbar(state, data) &#123;</span><br><span class="line">      state.isTabbarShow = data;</span><br><span class="line">    &#125;,</span><br><span class="line">    ShowTabbar(state, data) &#123;</span><br><span class="line">      state.isTabbarShow = data;</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  actions: &#123;</span><br><span class="line">    <span class="comment">//主要执行异步操作,</span></span><br><span class="line">    <span class="comment">// 如何调用：this.$store.dispatch("模块名/函数名称",[data])</span></span><br><span class="line">    test(store, data) &#123;</span><br><span class="line">      <span class="comment">//使用commit通过mutation中方法修改state</span></span><br><span class="line">      store.commit(<span class="string">""</span>, data);</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  getters: &#123;</span><br><span class="line">    <span class="comment">// store中的计算属性</span></span><br><span class="line">    <span class="comment">// 调用方式 $store.getters."函数名字"</span></span><br><span class="line">    getItemListTop3(state) &#123;</span><br><span class="line">      <span class="keyword">return</span> state.itemList.slice(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">    &#125;,</span><br><span class="line">  &#125;,</span><br><span class="line">  modules: &#123;</span><br><span class="line">    <span class="comment">//不同模块中可以定义state、mutations、actions，然后包装成一个对象导出，在这儿进行导入，注意在子模块中不需要使用Vuex.Store构造函数。</span></span><br><span class="line">      cart,</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> store;</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cart/index.js</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> state = &#123;</span><br><span class="line">  items: [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>],</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">const</span> getters = &#123;</span><br><span class="line">  getOddItem(state) &#123;</span><br><span class="line">    <span class="keyword">return</span> state.items.filter(<span class="function">(<span class="params">x</span>) =&gt;</span> x % <span class="number">2</span> == <span class="number">0</span>);</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">const</span> mutations = &#123;</span><br><span class="line">  incre(state) &#123;</span><br><span class="line">    state.items = state.items.map(<span class="function">(<span class="params">x</span>) =&gt;</span> x + <span class="number">2</span>);</span><br><span class="line">  &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;<span class="comment">//开启了命名空间</span></span><br><span class="line">  namespaced: <span class="literal">true</span>,</span><br><span class="line">  state,</span><br><span class="line">  getters,</span><br><span class="line">  mutations,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>在<code>main.js</code>中：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> store <span class="keyword">from</span> <span class="string">"@/store"</span>;</span><br><span class="line"></span><br><span class="line">Vue.config.productionTip = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> Vue(&#123;</span><br><span class="line">  store,</span><br><span class="line">  render: <span class="function">(<span class="params">h</span>) =&gt;</span> h(App),</span><br><span class="line">&#125;).$mount(<span class="string">"#app"</span>);</span><br></pre></td></tr></table></figure>
<p>​        <strong>注意：</strong></p>
<p>​        默认情况下，模块内部的 <strong>action、mutation 和 getter</strong> 是注册在<strong>全局命名空间</strong>的——这样使得多个模块能够对同一 mutation 或 action 作出响应。</p>
<p>​        <strong>即不论是在那个模块定义的，都可以使用</strong><code>this.$store.getters.名字</code>进行调用。如果希望你的模块具有更高的封装度和复用性，你可以通过添加 <code>namespaced: true</code> 的方式使其成为带命名空间的模块。当模块被注册后，它的所有 getter、action 及 mutation 都会自动根据模块注册的路径调整命名。即：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$store.getters[<span class="string">"cart/getOddItem"</span>]</span><br><span class="line">$store.dispatch(<span class="string">'cart/login'</span>)</span><br><span class="line">$store.commit(<span class="string">'cart/incre)</span></span><br></pre></td></tr></table></figure>
<p>​        可以看到，在vuex中，只允许mutation操作修改state，构成单向数据流。示意图如下：</p>
<p><img src="https://vuex.vuejs.org/vuex.png" alt=""></p>
<p><strong>补充：</strong></p>
<p>vue中计算属性（computed）和方法（methods）的区别：</p>
<p>计算属性以方法形式定义，使用时使用属性的方式进行调用；计算属性只会计算一次，结果缓存在内存中，当其相关联的数据发生改变时才会重新计算。而方法调用一次就会被执行一次。当有关数据处理逻辑较为复杂，或页面中需要多处使用时可以使用计算属性。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-ES6模块的导出和导入" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/05/22/ES6%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AF%BC%E5%87%BA%E5%92%8C%E5%AF%BC%E5%85%A5/"
    >ES6模块的导出和导入</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/22/ES6%E6%A8%A1%E5%9D%97%E7%9A%84%E5%AF%BC%E5%87%BA%E5%92%8C%E5%AF%BC%E5%85%A5/" class="article-date">
  <time datetime="2020-05-22T14:52:05.540Z" itemprop="datePublished">2020-05-22</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/JS/">JS</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="ES6模块的导出和导入"><a href="#ES6模块的导出和导入" class="headerlink" title="ES6模块的导出和导入"></a>ES6模块的导出和导入</h2><p>​    es6采用export、import进行模块的导出和导入。</p>
<p>​    假如有如下三个文件，处于相同目录下</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">A.js</span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">a1</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"a1 run"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">export</span> <span class="function"><span class="keyword">function</span> <span class="title">a2</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"a2 run"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> a3 = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//或者</span></span><br><span class="line"><span class="comment">// export &#123;a1,a2,a3&#125;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">B.js</span><br><span class="line"><span class="keyword">let</span> b1 = <span class="function"><span class="keyword">function</span>(<span class="params">data</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(data)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">b2</span>(<span class="params"></span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(<span class="string">"b2 run"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">export</span> <span class="keyword">const</span> b3 = <span class="number">6</span></span><br><span class="line"><span class="comment">//只可以使用一次 export default</span></span><br><span class="line"><span class="keyword">export</span> <span class="keyword">default</span> &#123;</span><br><span class="line">    b1,b2,b3</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">export</span> &#123;</span><br><span class="line">	b1,b3</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">main.js</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> &#123;a3, a2 <span class="keyword">as</span> myfunc&#125; <span class="keyword">from</span> <span class="string">"./A.js"</span></span><br><span class="line"><span class="keyword">import</span> MyB <span class="keyword">from</span> <span class="string">"./B.js"</span> </span><br><span class="line"><span class="keyword">import</span> &#123;b1,b3&#125; <span class="keyword">from</span> <span class="string">"./B.js"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(a3) <span class="comment">// 5</span></span><br><span class="line">myfunc() <span class="comment">// a2 run</span></span><br><span class="line"></span><br><span class="line">MyB.b2() <span class="comment">// b2 run</span></span><br><span class="line">MyB.b1(<span class="string">"hello world"</span>) <span class="comment">// hello world</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">console</span>.log(b3); <span class="comment">// 6</span></span><br><span class="line">b1(<span class="string">"word"</span>) <span class="comment">// word</span></span><br></pre></td></tr></table></figure>
<p><strong>说明：</strong></p>
<ol>
<li><p><code>export default</code>意味着将大括号中的函数、变量封装成default对象全部导出，且该语句在一个js文件中只可以使用一次。在另一个文件中导入时，导入名字可以随便写。</p>
</li>
<li><p><code>export</code> + 变量/常量/函数，部分导出；在另一个文件进行导入时，导入名称必须和模块中定义的相同，但是可以使用<code>as</code>进行重命名，注意导入时需要使用大括号（<code>ES6</code>中对象的解构赋值）。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> p = &#123;<span class="attr">name</span>:<span class="string">"bill"</span>, <span class="attr">age</span>: <span class="number">25</span>&#125;</span><br><span class="line"><span class="keyword">let</span> &#123;name,age&#125; = p <span class="comment">//变量名务必和对象属性名相同，否则会得到undefined</span></span><br><span class="line"><span class="built_in">console</span>.log(name + <span class="string">","</span> + age) <span class="comment">// bill 25</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">let</span> &#123;log&#125; = <span class="built_in">console</span></span><br><span class="line">log(<span class="string">"hello world"</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
    <article id="post-Pytorch学习笔记之卷积神经网络" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/05/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
    >Pytorch学习笔记之卷积神经网络</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/18/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B9%8B%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" class="article-date">
  <time datetime="2020-05-18T02:54:23.567Z" itemprop="datePublished">2020-05-18</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="Pytorch学习笔记之卷积神经网络"><a href="#Pytorch学习笔记之卷积神经网络" class="headerlink" title="Pytorch学习笔记之卷积神经网络"></a>Pytorch学习笔记之卷积神经网络</h2><h3 id="1-模型构建"><a href="#1-模型构建" class="headerlink" title="1 模型构建"></a>1 模型构建</h3><p>在<code>pytorch</code>中，我们构建的模型都继承自<code>torch.nn.Module</code>这个类，并且要重写其<code>forward</code>方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Network</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels=<span class="number">6</span>, out_channels=<span class="number">12</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">        self.fc1 = nn.Linear(in_features=<span class="number">12</span> * <span class="number">4</span> * <span class="number">4</span>, out_features=<span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(in_features=<span class="number">120</span>, out_features=<span class="number">60</span>)</span><br><span class="line">        self.out = nn.Linear(in_features=<span class="number">60</span>, out_features=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, t)</span>:</span></span><br><span class="line">        <span class="comment"># implement the forward pass</span></span><br><span class="line">        <span class="comment"># (1) input layer</span></span><br><span class="line">		t = t</span><br><span class="line">        <span class="comment"># (2) hidden conv layer</span></span><br><span class="line">        t = self.conv1(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        t = F.max_pool2d(t, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (3) hidden conv layer</span></span><br><span class="line">        t = self.conv2(t) <span class="comment"># [batch_size, channels, width, height]</span></span><br><span class="line">        </span><br><span class="line">        t = F.relu(t)</span><br><span class="line">        t = F.max_pool2d(t, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (4) hidden linear layer</span></span><br><span class="line">        t = t.reshape(<span class="number">-1</span>, <span class="number">12</span> * <span class="number">4</span> * <span class="number">4</span>)</span><br><span class="line">        t = self.fc1(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (5) hidden linear layer</span></span><br><span class="line">        t = self.fc2(t)</span><br><span class="line">        t = F.relu(t)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (6) output layer</span></span><br><span class="line">        t = self.out(t)</span><br><span class="line">        <span class="comment">#t = F.softmax(t, dim=1)</span></span><br><span class="line">        <span class="keyword">return</span> t</span><br><span class="line"></span><br><span class="line">&gt; network = Network()</span><br><span class="line">&gt; print(network)</span><br><span class="line">Network(</span><br><span class="line">  (conv1): Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (conv2): Conv2d(<span class="number">6</span>, <span class="number">12</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (fc1): Linear(in_features=<span class="number">192</span>, out_features=<span class="number">120</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (fc2): Linear(in_features=<span class="number">120</span>, out_features=<span class="number">60</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  (out): Linear(in_features=<span class="number">60</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">)</span><br><span class="line">&gt; network.conv1.weight.shape <span class="comment"># [channels,kernel_nums, kernel_size,kernel_size]</span></span><br><span class="line">torch.Size([<span class="number">6</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br><span class="line">&gt; network.conv2.weight.shape</span><br><span class="line">torch.Size([<span class="number">12</span>, <span class="number">6</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<p>总的来说，要经过 3 个步骤：</p>
<ol>
<li><p>继承<code>nn.Moudle</code></p>
</li>
<li><p>在<code>__init__(self)</code>方法中定义神经网络中的<code>layer</code>作为类的属性</p>
</li>
<li>实现<code>forward()</code>方法。</li>
</ol>
<p><strong>tips</strong>：一个多通道卷积与<strong>feature maps</strong>作卷积，结果是一个数值（每个通道卷积最后加起来），因此，<code>output_channels</code>的数量<strong>取决于卷积核的数量</strong>。每一层卷积的参数 = <code>channels * kernel_nums * size</code>。</p>
<p>在定义好模型结构后，就可以输入训练集进行迭代训练直至收敛。</p>
<p>上述网络结构中，<code>feature maps</code>尺寸变化如下：</p>
<p><img src="/images/feature——maps.png" alt=""></p>
<p><strong><code>feature_map</code>变换公式</strong>：</p>
<ul>
<li>图片大小 $W$</li>
<li>卷积核<code>filter</code>大小 $F$</li>
<li>步长<code>stride</code> 大小 $S$</li>
<li>填充<code>padding</code>大小 $P$</li>
<li><code>max_pooling</code>层 核大小 $f$</li>
<li><code>max_pooling</code>层步长 <code>stride</code> $s$</li>
</ul>
<p>经过卷积输出大小 $N$ 有：</p>
<script type="math/tex; mode=display">
N = \frac{W - F + 2P}{S} + 1</script><p>再经过<code>max_pooling</code> ,最终大小 $M$ ,有:</p>
<script type="math/tex; mode=display">
M = \frac{N-f}{s} + 1</script><p>注：<code>nn.Conv2d</code>输出维度：<code>[batch_size, channels, width, height]</code></p>
<h3 id="2-训练你的模型"><a href="#2-训练你的模型" class="headerlink" title="2 训练你的模型"></a>2 训练你的模型</h3><p><strong>训练流程</strong>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1. Get batch from the training set.</span><br><span class="line">2. Pass batch to network.</span><br><span class="line">3. Calculate the loss (difference between the predicted values and the true values).</span><br><span class="line">4. Calculate the gradient of the loss function w.r.t the network&#39;s weights.</span><br><span class="line">5. Update the weights using the gradients to reduce the loss.（反向传播）</span><br><span class="line">6. Repeat steps 1-5 until one epoch is completed.</span><br><span class="line">7. Repeat steps 1-6 for as many epochs required to reach the minimum loss.</span><br></pre></td></tr></table></figure>
<p><strong>batch</strong>：每次输入神经网络中的数据集数量。</p>
<p><strong>epoch</strong>：遍历完整个数据集称之为一个<code>epoch</code>。</p>
<p>整个流程代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> confusion_matrix</span><br><span class="line"><span class="comment">#from plotcm import plot_confusion_matrix</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pdb</span><br><span class="line"></span><br><span class="line">torch.set_printoptions(linewidth=<span class="number">120</span>)</span><br><span class="line"><span class="comment">#训练数据集的加载</span></span><br><span class="line">train_set = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">'./data'</span></span><br><span class="line">    ,train=<span class="literal">True</span></span><br><span class="line">    ,download=<span class="literal">True</span></span><br><span class="line">    ,transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor()</span><br><span class="line">    ])</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set</span><br><span class="line">    ,batch_size=<span class="number">1000</span></span><br><span class="line">    ,shuffle=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_num_correct</span><span class="params">(preds, labels)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> preds.argmax(dim=<span class="number">1</span>).eq(labels).sum().item()</span><br><span class="line"></span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line">network = Network()</span><br><span class="line">torch.set_grad_enabled(<span class="literal">True</span>)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(train_set, batch_size=<span class="number">100</span>)</span><br><span class="line">optimizer = optim.Adam(network.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 要遍历10次整个数据集</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    total_loss = <span class="number">0</span></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">	<span class="comment"># batchsize = 1000</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_loader: <span class="comment"># Get Batch</span></span><br><span class="line">        images, labels = batch</span><br><span class="line"></span><br><span class="line">        preds = network(images) <span class="comment"># Pass Batch</span></span><br><span class="line">        loss = F.cross_entropy(preds, labels) <span class="comment"># Calculate Loss</span></span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward() <span class="comment"># Calculate Gradients</span></span><br><span class="line">        optimizer.step() <span class="comment"># Update Weights</span></span><br><span class="line"></span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">        total_correct += get_num_correct(preds, labels)</span><br><span class="line"></span><br><span class="line">    print(</span><br><span class="line">        <span class="string">"epoch"</span>, epoch,</span><br><span class="line">        <span class="string">"total_correct:"</span>, total_correct,</span><br><span class="line">        <span class="string">"loss:"</span>, total_loss</span><br><span class="line">    )</span><br><span class="line">total_correct/len(train_set) <span class="comment"># 0.8858833333333334</span></span><br></pre></td></tr></table></figure>
<p>最后可以看出，在训练集上的准确率为 $88\%$ 左右。</p>
<p>输出如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">epoch <span class="number">0</span> total_correct: <span class="number">51138</span> loss: <span class="number">238.7455054372549</span></span><br><span class="line">epoch <span class="number">1</span> total_correct: <span class="number">52016</span> loss: <span class="number">216.4094382673502</span></span><br><span class="line">epoch <span class="number">2</span> total_correct: <span class="number">52269</span> loss: <span class="number">206.6615267843008</span></span><br><span class="line">epoch <span class="number">3</span> total_correct: <span class="number">52513</span> loss: <span class="number">201.51278421282768</span></span><br><span class="line">epoch <span class="number">4</span> total_correct: <span class="number">52504</span> loss: <span class="number">197.78098802268505</span></span><br><span class="line">epoch <span class="number">5</span> total_correct: <span class="number">52791</span> loss: <span class="number">192.42419914901257</span></span><br><span class="line">epoch <span class="number">6</span> total_correct: <span class="number">52802</span> loss: <span class="number">193.69900572299957</span></span><br><span class="line">epoch <span class="number">7</span> total_correct: <span class="number">53002</span> loss: <span class="number">187.62913002073765</span></span><br><span class="line">epoch <span class="number">8</span> total_correct: <span class="number">53087</span> loss: <span class="number">183.71526048332453</span></span><br><span class="line">epoch <span class="number">9</span> total_correct: <span class="number">53153</span> loss: <span class="number">182.18467965722084</span></span><br></pre></td></tr></table></figure>
<p>在测试集上的表现如何？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">test_set = torchvision.datasets.FashionMNIST(</span><br><span class="line">    root=<span class="string">'./data'</span>,</span><br><span class="line">    train= <span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">False</span>,</span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.ToTensor()])</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(test_set,batch_size=<span class="number">500</span>,shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">global</span> correct</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> test_loader:</span><br><span class="line"></span><br><span class="line">        images,labels = batch</span><br><span class="line">        preds = network(images)</span><br><span class="line">        preds = preds.argmax(dim = <span class="number">1</span>)</span><br><span class="line">        correct += (preds == labels).sum()</span><br><span class="line">        print(correct)</span><br><span class="line">print(correct.item() *<span class="number">1.0</span> / len(test_set)) <span class="comment">#0.8631</span></span><br></pre></td></tr></table></figure>
<p>在测试集上的准确率为 $86.31\%$。仍然有很大改善空间。</p>
<p>下面观察以下经过<code>conv1</code>、<code>conv2</code>后的<code>feature maps</code>。（没有经过最大池化）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">sets = iter(train_loader)</span><br><span class="line">batch = next(sets)</span><br><span class="line">images,labels = batch</span><br><span class="line">input = images[<span class="number">0</span>].unsqueeze(<span class="number">0</span>) <span class="comment">#[1, 1, 28, 28] 升维，增加一个维度 batch</span></span><br><span class="line">network = Network()</span><br><span class="line">feature1 = network.conv1(input)</span><br><span class="line">feature2 = network.conv2(feature1)</span><br><span class="line">feature1_ = feature1.squeeze() <span class="comment">#[6,24,24]</span></span><br><span class="line">feature2_ = feature2.squeeze() <span class="comment">#[12,20,20]</span></span><br><span class="line"></span><br><span class="line">ch1 = feature1_[<span class="number">5</span>]</span><br><span class="line">ch1_ = ch1.data.numpy()</span><br><span class="line">ch2 = feature2_[<span class="number">5</span>]</span><br><span class="line">ch2_ = ch2.data.numpy()</span><br><span class="line"></span><br><span class="line">plt.imshow(ch1_)</span><br><span class="line">plt.show()</span><br><span class="line">plt.imshow(ch2_)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/images/f1_6.png" alt=""></p>
<center>conv1后第6通道的feature</center>

<p><img src="/images/f2_6.png" alt=""></p>
<center>conv2后第6通道的feature</center>

<h3 id="3-记点其他的知识"><a href="#3-记点其他的知识" class="headerlink" title="3 记点其他的知识"></a>3 记点其他的知识</h3><h4 id="3-1-Batch-Normalization"><a href="#3-1-Batch-Normalization" class="headerlink" title="3.1 Batch Normalization"></a>3.1 Batch Normalization</h4><p>在<code>Pytorch</code>中，位于<code>torch.nn</code>包下。[ <a href="https://pytorch.org/docs/stable/nn.html#batchnorm2d" target="_blank" rel="noopener">https://pytorch.org/docs/stable/nn.html#batchnorm2d</a> ]</p>
<p><strong>提出原因</strong>：解决梯度消失问题， 加速训练收敛过程 。</p>
<p><strong>原理</strong>：将隐层的输入分布变为均值为 $0$ ，方差为 $1$ 的正态分布。</p>
<p>设$X = \{x_1,x_2,…,x_m\}$表示$X$的维度。$m$ 代表 $batch-size$.</p>
<script type="math/tex; mode=display">
x = Wu + b</script><p>计算样本每个维度均值：</p>
<script type="math/tex; mode=display">
\mu_B = \frac{1}{m} \sum_{i = 1}^{m} x_i</script><p>计算样本每个维度的方差：</p>
<script type="math/tex; mode=display">
\sigma_B^2 = \frac{1}{m} \sum_{i = 1}^{m} (x_i - \mu_B)^2</script><script type="math/tex; mode=display">
\hat x_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}</script><script type="math/tex; mode=display">
y_i = \gamma\hat x_i + \beta = BN_{\gamma,\beta}(x_i)</script><p>其中，$\gamma$、$\beta$ 是通过学习得到的。</p>
<p><strong>如何操作</strong>：即将<code>input</code>与<code>weight matrix</code>相乘后，再作为激活函数的输入。在<code>CNN</code>中，是做完卷积操作后，激活函数之前。在训练时，均值、方差都是训练时<code>batch</code>的统计数据，可以记下然后做加权平均得到测试时使用的均值和方差，在测试时使用。</p>
<p><img src="/images/20160522210927345.png" alt=""></p>
<center>全连接层，bn层的位置</center>

<p><img src="/images/cnn-bn.png" style="zoom:70%;" /></p>
<center>一般卷积操作中，bn层的位置</center>

<p><strong>进一步的理解</strong>：</p>
<p>在原论文<code>3.2</code>节，作者提到 $BN$ 通常加入到<strong>非线性单元（激活函数）之前</strong>，对 $Wu + b$ 进行<code>normalizing</code>，而不是 $u$，作者是这样解释的：$u$ 可能是上一个非线性单元的输出，非线性单元的输出分布形状会在训练过程中变化，归一化无法消除他的方差偏移。</p>
<p>而对于 $Wu+b$ （线性变换，卷积操作也是线性变换）这种变换的输出一般是一个对称，非稀疏的一个分布，更加类似高斯分布，对他们进行归一化会产生更加稳定的分布。</p>
<p>看一下 $W u + b$ 经过$BN$后，参数 $b$ 的变化：</p>
<script type="math/tex; mode=display">
\mu = \frac{1}{m} \sum_{i = 1}^{m} Wu_i + b = \frac{1}{m}\sum_{i=1}^{m}Wu_i + \frac{bm}{m}</script><script type="math/tex; mode=display">
\hat x_i = \frac{Wu_i + b- \mu}{\sqrt{\sigma^2 + \epsilon}} = \frac{Wu_i - \frac{1}{m}\sum_{i=1}^{m}Wu_i}{\sqrt{\sigma^2 + \epsilon}}</script><p>可以看到参数$b$最后被消掉了，可有可无。因此可以表示为：</p>
<script type="math/tex; mode=display">
z = g(BN(Wu + b)) \rightarrow z = g(BN(Wu))</script><p><strong>We could have also normalized the layer inputs u, but since u is likely the output of another nonlinearity, the shape of its distribution is likely to change during training, and constraining its first and second moments would not eliminate the co-variate shift.</strong></p>
<p><strong>In contrast, Wu + b is more likely to have a symmetric, non-sparse distribution, that is “more Gaussian”; normalizing it is likely to produce activations with a stable distribution.</strong></p>
<p><strong>经过卷积后怎么 BN</strong></p>
<p>通常经过卷积操作后，会产生多个<code>channel</code>。将每个<code>channel</code>视为一个维度，统计<code>channel</code>内所有样本的均值和方差，这样每个<code>channel</code>对应一对参数$\gamma,\beta$。比如：<code>[batch_size,channel,width,height]</code>，每个<code>channel</code>内，<code>batch_size * width * height</code>的均值和方差。</p>
<h4 id="3-2-Dropout"><a href="#3-2-Dropout" class="headerlink" title="3.2 Dropout"></a>3.2 Dropout</h4><p>在<code>Pytorch</code>中，位于<code>torch.nn</code>包下。</p>
<p><strong>提出原因</strong>：解决过拟合问题。</p>
<h4 id="3-3-卷积数学定义"><a href="#3-3-卷积数学定义" class="headerlink" title="3.3 卷积数学定义"></a>3.3 卷积数学定义</h4><p><strong>离散卷积</strong></p>
<script type="math/tex; mode=display">
(f*g)(n) = \sum_{\tau = -m}^{m} f(\tau)g(n-\tau)</script><p><strong>连续卷积</strong></p>
<script type="math/tex; mode=display">
(f*g)(n) = \int_{\tau = -m}^{\tau = m} f(\tau)g(n-\tau)</script><p>事实上，我们在二维卷积的时候，使用的卷积核<script type="math/tex">(g)</script>是经过反转后的，为了方便计算。在进行一维卷积时，也需要对核进行反转（左右反转）。</p>
<p>参考：<a href="https://www.cnblogs.com/itmorn/p/11177439.html" target="_blank" rel="noopener">https://www.cnblogs.com/itmorn/p/11177439.html</a></p>
<p>计算：<a href="https://www.nowcoder.com/questionTerminal/0a3fc6ff7d89441db100fdd00ce22132?orderByHotValue=1&amp;page=1&amp;onlyReference=false" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/0a3fc6ff7d89441db100fdd00ce22132?orderByHotValue=1&amp;page=1&amp;onlyReference=false</a></p>
<h4 id="3-4-Attention-机制"><a href="#3-4-Attention-机制" class="headerlink" title="3.4 Attention 机制"></a>3.4 Attention 机制</h4><p><strong>传统 Encoder-Decoder 模型</strong>：</p>
<p> 在传统的模型中， 我们仅使用 Encoder 的最后一个隐状态作为 Decoder 的初始隐状态，Encoder 最后的隐状态被称为<strong>context vector</strong>向量，因为他对整个输入的 sentence 做了一个编码。在之后的 Decoder 模型中，<code>Decoder</code>初始<code>input</code>为<code>SOS(start of string) token</code>，初始隐状态为这个 context vector，然后接受上一次的<code>output</code>作为<code>input</code>迭代完成训练。</p>
<p><img src="/images/encoder-decoder.png" alt=""></p>
<p><strong>加入了 Attention 机制的 Encoder-Decoder 模型</strong>：</p>
<p> 标准$seq2seq$模型通常无法准确处理长输入序列，因为只有编码器的最后一个隐藏状态被用作解码器的上下文向量。 另一方面，注意力机制在解码过程中保留并利用了输入序列的所有隐藏状态(context vector)，因此直接解决了此问题。 它通过在解码器输出的每个时间步长到所有编码器隐藏状态之间创建唯一的映射来实现此目的。 这意味着，对于解码器产生的每个输出，它都可以访问整个输入序列，并且可以从该序列中有选择地选择特定元素以产生输出。 相对于传统 LSTM 记忆网络处理长度较长的序列，加入 Attention 后参数减少。</p>
<p><img src="/images/1152PYf.png" alt=""></p>
<p> Attention 机制分为不同的种类，但总的来说大概分为以下几步：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.</span> Calculating Alignment Scores</span><br><span class="line"><span class="number">2.</span> Softmaxing alignment scores to get Attention weights（归一化）</span><br><span class="line"><span class="number">3.</span> Multiplying the Attention weights <span class="keyword">with</span> encoder outputs/all hidden states to get the context vector(加权求和)</span><br><span class="line"><span class="number">4.</span> Concatenating context vector <span class="keyword">with</span> embedded input word</span><br></pre></td></tr></table></figure>
<p>具体实现参考：</p>
<p><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html" target="_blank" rel="noopener">https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html</a></p>
<p><a href="https://blog.floydhub.com/attention-mechanism/" target="_blank" rel="noopener">https://blog.floydhub.com/attention-mechanism/</a></p>
<p><img src="/images/attention-decoder-network.png" alt=""></p>
<p> 下面介绍<strong>NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</strong>论文中提到的 Attention 机制。</p>
<ul>
<li><p>首先将序列经过 Encoder 模型，产生所有隐状态$H_{Encoder}$</p>
</li>
<li><p>计算 Alignment Scores:</p>
<p>在 Decoder 模型中，时间 $i$ 对应的前一个隐状态为$s_{i-1}$，</p>
<script type="math/tex; mode=display">
e_{ij} = \alpha(s_{i-1},h_j),j=1,2,3,...,T_x</script><p>表示不同$h_j$对$s_{i}$的影响程度。即将 $s_{i-1}$ 与每一个 Encoder 的隐状态经过一个函数得到输出，这个函数的参数通过学习得到。</p>
</li>
<li><p>$soft\max$归一化，得到 attention weights</p>
<script type="math/tex; mode=display">
\alpha_{ij} = \frac{\exp(e_{ij})}{\sum_{k=1}^{T_X} \exp(e_{ik})}</script></li>
</ul>
<ul>
<li><p>计算 context vector:</p>
<script type="math/tex; mode=display">
c_i = \sum_{j=1}^{T_x} \alpha_{ij}h_j</script><p><strong>注意</strong>：此时$c_i$仍是一个多维向量，相加的时候是各个维度分别相加。</p>
</li>
<li><p>将 context vector 与$t-1$的 output 作为输入（ _concatenated_ ），与$s_{i-1}$传入 decoder 模型中得到输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># 所有encoder隐状态 共有3个隐态，维度为4</span></span><br><span class="line">hidden_states = np.array([</span><br><span class="line">    [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>],</span><br><span class="line">    [<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>],</span><br><span class="line">    [<span class="number">0</span>,<span class="number">-1</span>,<span class="number">3</span>,<span class="number">6</span>]</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 得出的attention权重</span></span><br><span class="line">weights = np.array([[<span class="number">0.6</span>,<span class="number">0.3</span>,<span class="number">0.1</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># weights和hidden_states 相乘</span></span><br><span class="line">np.dot(weights,hidden_states)</span><br><span class="line"><span class="comment">#各个维度相加得到context_vector</span></span><br><span class="line">array([[<span class="number">1.2</span>, <span class="number">2.</span> , <span class="number">3.6</span>, <span class="number">5.1</span>]])</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><img src="/images/attn_mem.jpeg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BahdanauDecoder</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, hidden_size, output_size, n_layers=<span class="number">1</span>, drop_prob=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    super(BahdanauDecoder, self).__init__()</span><br><span class="line">    self.hidden_size = hidden_size</span><br><span class="line">    self.output_size = output_size</span><br><span class="line">    self.n_layers = n_layers</span><br><span class="line">    self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    self.embedding = nn.Embedding(self.output_size, self.hidden_size)</span><br><span class="line"></span><br><span class="line">    self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=<span class="literal">False</span>)</span><br><span class="line">  </span><br><span class="line">    self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=<span class="literal">False</span>)</span><br><span class="line">    <span class="comment">#也可以用nn.Linear代替</span></span><br><span class="line">    self.weight = nn.Parameter(torch.FloatTensor(<span class="number">1</span>, hidden_size))</span><br><span class="line">    self.attn_combine = nn.Linear(self.hidden_size * <span class="number">2</span>, self.hidden_size)</span><br><span class="line">    self.dropout = nn.Dropout(self.drop_prob)</span><br><span class="line">    self.lstm = nn.LSTM(self.hidden_size*<span class="number">2</span>, self.hidden_size, batch_first=<span class="literal">True</span>)</span><br><span class="line">    self.classifier = nn.Linear(self.hidden_size, self.output_size)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, inputs, hidden, encoder_outputs)</span>:</span></span><br><span class="line">    encoder_outputs = encoder_outputs.squeeze()</span><br><span class="line">    <span class="comment"># Embed input words</span></span><br><span class="line">    embedded = self.embedding(inputs).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    embedded = self.dropout(embedded)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Calculating Alignment Scores</span></span><br><span class="line">    x = torch.tanh(self.fc_hidden(hidden[<span class="number">0</span>])+self.fc_encoder(encoder_outputs))</span><br><span class="line">    alignment_scores = x.bmm(self.weight.unsqueeze(<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Softmaxing alignment scores to get Attention weights</span></span><br><span class="line">    attn_weights = F.softmax(alignment_scores.view(<span class="number">1</span>,<span class="number">-1</span>), dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Multiplying the Attention weights with encoder outputs to get the context vector</span></span><br><span class="line">    context_vector = torch.bmm(attn_weights.unsqueeze(<span class="number">0</span>),</span><br><span class="line">                             encoder_outputs.unsqueeze(<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Concatenating context vector with embedded input word</span></span><br><span class="line">    output = torch.cat((embedded, context_vector[<span class="number">0</span>]), <span class="number">1</span>).unsqueeze(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Passing the concatenated vector as input to the LSTM cell</span></span><br><span class="line">    output, hidden = self.lstm(output, hidden)</span><br><span class="line">    <span class="comment"># Passing the LSTM output through a Linear layer acting as a classifier</span></span><br><span class="line">    output = F.log_softmax(self.classifier(output[<span class="number">0</span>]), dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> output, hidden, attn_weights</span><br></pre></td></tr></table></figure>
<h3 id="4-卷积网络之电影评论情感分类"><a href="#4-卷积网络之电影评论情感分类" class="headerlink" title="4. 卷积网络之电影评论情感分类"></a>4. 卷积网络之电影评论情感分类</h3><p>​        参考：<a href="https://github.com/bentrevett/pytorch-sentiment-analysis" target="_blank" rel="noopener">https://github.com/bentrevett/pytorch-sentiment-analysis</a></p>
<p>​        采用<code>IMDB</code>数据集，使用<code>glove.6B.100d</code>预训练好的词向量。label总共有两类：消极评价：<code>neg</code>，积极评价：<code>pos</code>。</p>
<p>​        使用卷积网络用来扫描词向量组成的矩阵，即使用过滤器（filters）扫描embedding矩阵，这里介绍的模型使用三个大小不同的filter，每个filter共100个，filter的宽度和embedding_dim相同，高度分为3、4、5，即filter每次扫描的单词个数分别为3、4、5，filter每次移动1个单词距离。最后的向量shape为<code>[lenth_of_the_word  - height_of_the_filter + 1, 1]</code>。将经过不同filter后的向量拼接起来然后经过全连接得到最终的预测结果。</p>
<p><img src="/images/sentiment.png" alt="filter示意图"></p>
<p><img src="/images/网络结构.jpg" alt=""></p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  

  

  

</article>
    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2019-2020
        张永剑
      </li>
      <li>
        
          Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <ul class="list-inline">
  <li>PV:<span id="busuanzi_value_page_pv"></span></li>
  <li>UV:<span id="busuanzi_value_site_uv"></span></li>
</ul>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
      <aside class="sidebar">
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="张永剑的博客"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>







<script>
  var ayerConfig = {
    mathjax: true
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>



<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>