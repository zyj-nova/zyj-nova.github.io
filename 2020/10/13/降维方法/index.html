<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
    
  <meta name="description" content="天空如此辽阔，大地不过是必经之路" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    降维方法 |  张永剑的博客
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>


  

  

<link rel="alternate" href="/atom.xml" title="张永剑的博客" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    <main class="content">
      <section class="outer">
  <article id="post-降维方法" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  降维方法
</h1>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/10/13/%E9%99%8D%E7%BB%B4%E6%96%B9%E6%B3%95/" class="article-date">
  <time datetime="2020-10-13T11:25:37.660Z" itemprop="datePublished">2020-10-13</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
  </div>

      
      
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">2.5k字</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">11分钟</span>
        </span>
    </span>
</div>

      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="降维方法"><a href="#降维方法" class="headerlink" title="降维方法"></a>降维方法</h2><h3 id="1-主成分分析"><a href="#1-主成分分析" class="headerlink" title="1. 主成分分析"></a>1. 主成分分析</h3><h4 id="1-1-算法分析"><a href="#1-1-算法分析" class="headerlink" title="1.1 算法分析"></a>1.1 算法分析</h4><p>已知样本$\pmb a_1,\pmb a_2,…,\pmb a_N,\pmb a_i \in \mathbb{R}^n$，则按列组成的矩阵:</p>
<script type="math/tex; mode=display">
A_{n \times m} = \begin{pmatrix}\pmb a_1,&\pmb a_2,...&,\pmb a_N\end{pmatrix}</script><p><strong>矩阵的弗罗贝尼乌斯范数</strong>：</p>
<script type="math/tex; mode=display">
||A||_2 = \sqrt {tr (A^TA)} = \sqrt{\sum_{i=1}^m\sum_{j=1}^na_{ij}^2}</script><p>$tr$代表矩阵的迹函数$trace$（主对角线元素求和，$A^TA$一定是个方阵）。</p>
<p>给定一组标准正交基$\pmb w_1,\pmb w_2,…,\pmb w_N,\pmb w_i \in \mathbb{R}^n$，$\mathbb{R}^n$中的某个向量$\pmb a$可以表示为：</p>
<script type="math/tex; mode=display">
\pmb a = \sum_{j = 1}^n <\pmb a,\pmb w_j>\pmb w_j</script><p>$&lt;,&gt;$表示向量的内积操作，可以看出$&lt;\pmb a,\pmb w_j&gt;$即$\pmb a$在空间中的坐标。现在我们考虑，是否可以将$\pmb a$表示在由$\pmb w_1,\pmb w_2,…,\pmb w_m,m \mathbb{&lt;&lt;} n$，生成的子空间$\mathbb{R}^m$中，使得$&lt;\pmb a,\pmb w_{m+1}&gt;=0,…,&lt;\pmb a, \pmb w_n&gt; = 0$ ?也就是说只需要前$m$个基就可以表示$\pmb a$。</p>
<p><strong>降维准则：</strong> 找到一组基，使得数据在这组基表示下，$m+1,…n$维的坐标都是0。</p>
<p><strong>注意：</strong>$\pmb w_i$仍然是包含$n$个分量的向量，$m$个包含$n$个元素基向量构成了$n$维空间的一个$m$维子空间（空间的维数等于基向量个数）。</p>
<p>这就可以将问题转化为一个优化问题：</p>
<script type="math/tex; mode=display">
\min_{\pmb w_1,\pmb w_2,...,\pmb w_m} = \sum_{i=1}^N ||\pmb a_i - \sum_{j=1}^m<\pmb a_i,\pmb w_j>\pmb w_j||_2^2\\
s.t.<\pmb w_i,\pmb w_j> = \delta_{ij},i=j,\delta_{ij}=1;i\not=j,\delta_{ij}=0</script><p>写为矩阵形式即：</p>
<script type="math/tex; mode=display">
\arg \min_{\pmb w_1,\pmb w_2,...,\pmb w_m} = ||A-WW^TA||_2^2\\
s.t. W^TW = I_{m \times m}</script><p>其中，$A$为数据的特征矩阵，$W_{n \times m}$为前$m$个正交基按列组成的矩阵，它是半正交的。</p>
<p><strong>tips：</strong>因为有$m$个基向量，两两相乘，最后矩阵是一个$m \times m$的单位阵。</p>
<script type="math/tex; mode=display">
||A-WW^TA||_2^2 = tr\{(A-WW^TA)^T(A-WW^TA)\} = tr(A^TA) - tr(A^TWW^TA)</script><p>由于$tr(A^TA)$这一项与优化目标无关，因此目标函数变为：</p>
<script type="math/tex; mode=display">
\arg\min_{W}-tr(A^TWW^TA) = -tr\{(W^TA)^T(W^TA)\} = -||W^TA||^2_2\\s.t: W^TW = I</script><p>求出最忧$W$后，降维数据：</p>
<script type="math/tex; mode=display">
Y_{m \times N} = W_{m \times n}^TX_{n\times N}</script><p>以上推导过程从<strong>基向量</strong>、最优化角度解释了主成分分析算法。</p>
<p><strong>注意：</strong>主成分分析是无监督、线性的降维方法。线性判别分析是有监督的线性降维方法。</p>
<p><strong>说明：</strong>降维后的空间与原空间没有对应关系，主成分是原始维度的线性组合得到。</p>
<h4 id="1-2-算法描述"><a href="#1-2-算法描述" class="headerlink" title="1.2 算法描述"></a>1.2 算法描述</h4><p><img src="https://img-blog.csdnimg.cn/20191109182949751.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05FRlVaWUo=,size_16,color_FFFFFF,t_70" alt="img"></p>
<p><img src="https://img-blog.csdnimg.cn/20191109191048929.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05FRlVaWUo=,size_16,color_FFFFFF,t_70" alt="img"></p>
<h4 id="1-3-sklearn中的PCA"><a href="#1-3-sklearn中的PCA" class="headerlink" title="1.3 sklearn中的PCA"></a>1.3 sklearn中的PCA</h4><p>PCA位于$sklearn.decomposition$包下。</p>
<p>注意“explained_variance_ratio_”这个指标，表示了原始数据在不同主成分上的方差占比（保留了多少原始数据的方差信息）。</p>
<p>扩展的PCA：Incremental PCA，当数据量特别大无法一次性加载至内存进行奇异值分解时，可以将数据划分为多个mini-batch，然后进行降维。</p>
<p>Kernel PCA：非线性降维。</p>
<p><strong>Question: Can PCA  be used to reduce the dimensionality of a highly nonlinear dataset？</strong></p>
<p><strong>Answer</strong>: PCA can be used to significantly reduce the dimensionality of most datasets, even if they are highly nonlinear, because it can at least get rid of useless dimensions. However, if there are no useless dimensions — for example, the Swiss roll — then reducing dimensionality with PCA will lose too much information. You want to unroll the Swiss roll, not squash it</p>
<h3 id="2-非负矩阵分解"><a href="#2-非负矩阵分解" class="headerlink" title="2. 非负矩阵分解"></a>2. 非负矩阵分解</h3><p>非负矩阵分解：Nonnegative Matrix Factorization</p>
<script type="math/tex; mode=display">
\min ||X - WH||^2\\
s.t.W>=0,H>=0</script><h3 id="3-局部线性嵌入"><a href="#3-局部线性嵌入" class="headerlink" title="3. 局部线性嵌入"></a>3. 局部线性嵌入</h3><p>局部线性嵌入：Locally Linear Embedding（LLE），<strong>属于非线性降维</strong></p>
<p>参考： <a href="https://www.cnblogs.com/pinard/p/6266408.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/p/6266408.html</a></p>
<p>流形学习（manifold learning）第一次听说”manifold”是在学习生成对抗网络的时候看到的。</p>
<p>推导过程中需要注意的地方：</p>
<p>下图中由$(1)\rightarrow(2)$过程中，因为$\sum_{j\in Q(i)}w_{ij} = 1$，所以$x_i = x_i \times 1 = \sum_{j\in Q(i)}w_{ij}x_i$。</p>
<p><img src="E:\hexo\themes\ayer\source\images\image-20201013195547190.png" alt="image-20201013195547190"></p>
<p><strong>算法描述</strong>：</p>
<h3 id="4-线性判别分析"><a href="#4-线性判别分析" class="headerlink" title="4. 线性判别分析"></a>4. 线性判别分析</h3><p>线性判别分析：Linear Discriminate Analysis（LDA）</p>
<p>降维原则：<strong>投影后</strong>最小化类内方差，最大化类间方差。属于线性、有监督的降维方法。</p>
<p>参考：<a href="https://www.jianshu.com/p/13ec606fdd5f" target="_blank" rel="noopener">https://www.jianshu.com/p/13ec606fdd5f</a> （二分类为例）</p>
<p>样本集：$\{(\pmb x_1,y_1),(\pmb x_2,y_2),…,(\pmb x_N,y_N)\},\pmb x_i \in \mathbb{R}^n$形成的样本矩阵$X_{n \times N}$，降维后数据$\pmb y$是一个$N \times 1$的向量</p>
<p>各个类的均值向量：</p>
<script type="math/tex; mode=display">
\pmb \mu_0 = \frac{1}{N_0}\sum_{\pmb x\in {0}}\pmb x\\
\pmb \mu_1 = \frac{1}{N_1}\sum_{\pmb x\in {1}}\pmb x</script><p>降维后的均值向量：</p>
<script type="math/tex; mode=display">
\tilde {\pmb \mu_0} = \frac{1}{N_0}\sum_{\pmb y\in 0}\pmb y =\frac{1}{N_0}\sum_{\pmb y\in 0}\pmb w^T\pmb x = \pmb w^T\pmb \mu_0</script><p>$\pmb w_{n \times 1}$就是我们要求的降维变换，同理：</p>
<script type="math/tex; mode=display">
\tilde {\pmb \mu_1} = \pmb w^T\pmb \mu_1</script><p>类内方差：</p>
<script type="math/tex; mode=display">
\tilde s_i^2 = \sum (\pmb y - \tilde{\pmb {\mu_i})^2}) = \sum (\pmb w^T\pmb x - \pmb w^T\pmb \mu_i)^2</script><p>即：</p>
<script type="math/tex; mode=display">
\tilde s_i^2 = \sum_{\pmb x\in i}[\pmb w^T(\pmb x - \pmb \mu_i)]^2 = \sum_{\pmb x\in i} [\pmb w^T(\pmb x-\pmb \mu_i)]^T[\pmb w^T(\pmb x-\pmb \mu_i)] = \sum_{\pmb x\in i} (\pmb x -\pmb \mu_i)^T\pmb w\pmb w^T(\pmb x-\pmb \mu_i)\\=\sum_{\pmb x\in i}\pmb w^T(\pmb x - \pmb \mu_i)(\pmb x - \pmb \mu_i)^T\pmb w</script><p><strong>说明：</strong>因为$(\pmb x -\pmb \mu_i)^T\pmb w$与$\pmb w^T(\pmb x-\pmb \mu_i)$ 结果分别是两个实数，可以交换。</p>
<p>令</p>
<script type="math/tex; mode=display">
\sum_{\pmb x\in i}(\pmb x - \pmb \mu_i)(\pmb x - \pmb \mu_i)^T = S_i</script><p>根据投影后类内方差小（$\tilde s_1^2 + \tilde s_0^2$ 两个都要小总体才能小），类间方差大（$||\pmb \mu_1 - \pmb \mu_2||^2$）。可以写出目标函数：</p>
<script type="math/tex; mode=display">
\max J(\pmb w) = \max \frac{||\pmb \mu_1 - \pmb \mu_2||^2}{\tilde s_1^2 + \tilde s_0^2}</script><p>并且根据上面的式子有：</p>
<script type="math/tex; mode=display">
\tilde s_1^2 + \tilde s_0^2 = \pmb w^T(S_0 + S_1)\pmb w =\pmb w^TS_W\pmb w = \tilde S_w</script><p>$S_W$：类内方差（with class）维度：$n \times n$</p>
<p>对于分子，我们有：</p>
<script type="math/tex; mode=display">
||\pmb \mu_1 - \pmb \mu_2||^2 = (\pmb w^T\pmb \mu_1 - \pmb w^T\pmb \mu_2)^2=\pmb w^T(\pmb \mu_1-\pmb \mu_2)(\pmb \mu_1-\pmb \mu_2)^T\pmb w</script><p>令：</p>
<script type="math/tex; mode=display">
(\pmb \mu_1-\pmb \mu_2)(\pmb \mu_1-\pmb \mu_2)^T = S_B</script><p>$S_B$：类间方差（between class）维度：$n \times n$</p>
<p>所以：</p>
<script type="math/tex; mode=display">
||\pmb \mu_1 - \pmb \mu_2||^2  = \pmb w^TS_B\pmb w = \tilde S_B</script><p>目标函数变为：</p>
<script type="math/tex; mode=display">
\max_{\pmb w} \frac{\pmb w^TS_B\pmb w}{\pmb w^TS_W\pmb w }</script><p>对$J(\pmb w)$对$\pmb w$求导并令其等于0即：</p>
<script type="math/tex; mode=display">
2S_B\pmb w(\pmb w^TS_W\pmb w)-2S_W\pmb w(\pmb w^TS_B\pmb w) = 0</script><p>注意：$\pmb w^TS_W\pmb w,\pmb w^TS_B\pmb w$结果都是实数，因此等式两边同除$\pmb w^TS_B\pmb w$可得：</p>
<script type="math/tex; mode=display">
S_W\pmb w =\frac{\pmb w^TS_W\pmb w}{\pmb w^TS_B\pmb w} S_B\pmb w</script><script type="math/tex; mode=display">
\pmb w = CS_W^{-1}S_B\pmb w</script><p>注意到：</p>
<script type="math/tex; mode=display">
S_B\pmb w =(\pmb \mu_1-\pmb \mu_2)(\pmb \mu_1-\pmb \mu_2)^T\pmb w</script><p>且$(\pmb \mu_1-\pmb \mu_2)^T\pmb w$结果是一个实数，C也是实数，我们要求的最关键的是$\pmb w$的方向，这些实数并不会改变方向，因此</p>
<script type="math/tex; mode=display">
\pmb w^* = S_W^{-1}(\pmb \mu_1 - \pmb \mu_2)</script><h3 id="5-多维尺度分析"><a href="#5-多维尺度分析" class="headerlink" title="5. 多维尺度分析"></a>5. 多维尺度分析</h3><p>Multidimensional Scaling</p>
<p>基本思想：尽量满足原始高维度空间中样本之间的距离在低维空间中得以保持。</p>
<p>“metric” or “non-metric”</p>
<p>给定样本$(\pmb x_1,\pmb x_2,…,\pmb x_N),\pmb x_i \in \mathbb{R}^n$构成的样本矩阵$X_{n \times N}$，降维后的样本矩阵$Y_{m \times N}$。根据多维尺度分析的基本思想：保持样本间距离不变，原始样本间距离$d_{ij}=||\pmb x_i - \pmb x_j||$构成的矩阵$D_{N \times N}$。</p>
<p>可知$X^TX = -\frac{1}{2}HD_xH, Y^TY = \frac{1}{2}HD_yH$，我们想让$D_x=D_y$，等价的可以通过以下目标函数来求得：</p>
<p>目标函数：</p>
<script type="math/tex; mode=display">
\min ||X^TX - Y^TY||^2</script><p>特征值分解：</p>
<script type="math/tex; mode=display">
X^TX = U^T\Lambda U</script><p>那么降维后的数据$Y$：</p>
<script type="math/tex; mode=display">
Y = \Lambda^{1/2}U</script><h3 id="6-典型关联分析"><a href="#6-典型关联分析" class="headerlink" title="6. 典型关联分析"></a>6. 典型关联分析</h3><p>Canonical correlation analysis</p>
<p>参考：<a href="https://www.cnblogs.com/pinard/articles/6288716.html" target="_blank" rel="noopener">https://www.cnblogs.com/pinard/articles/6288716.html</a></p>
<p>具体思想：相关系数 $\rho$ 可以分析两组一维数据$X,Y$的线性相关性，$\rho$取值越接近1则$X,Y$的线性相关性越高。虽然相关系数可以很好的帮我们分析一维数据的相关性，但是对于高维数据就不能直接使用了。比如$X$是2维数据，$Y$是三维数据，就不能用相关系数进行分析。那么有没有变通的方法呢？典型关联分析给出了思路，具体就是将多维的$X,Y$分别用线性变换为1维的$X^\prime,Y^\prime$，然后使用相关系数分析1维$X^\prime,Y^\prime$的相关性。问题又来了，如何把$X,Y$变换为$X^\prime，Y^\prime$呢？也就是说降维的准则是什么？<strong>典型关联分析使用的准则是变换到1维后，$X^\prime,Y^\prime$的相关系数最大。</strong></p>
<p>亦即：</p>
<script type="math/tex; mode=display">
arg \max_{\pmb a,\pmb b} ||X^T\pmb a - Y^T\pmb b||^2</script><p><strong>算法描述</strong>：</p>
<h3 id="7-字典学习"><a href="#7-字典学习" class="headerlink" title="7. 字典学习"></a>7. 字典学习</h3><p>参考：<a href="https://zhuanlan.zhihu.com/p/46085035" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/46085035</a></p>
<p><strong>基本思想：</strong></p>
<p>在人类发展的近几千年历史中，文字对人类文明的推动起着举足轻重的作用。人类用文字记述了千年的历史，用文字留下了各种思想火花，用文字抒发了各种各样的情感等等。但是这一切的内容，只需要一本字典就能表述完。因为人在这环节中的功能，无非就是使用字典当中的字词进行了适当的排列了而已。</p>
<p>基于这种思想，先前的大佬提出了字典学习——Dictionary Learning。</p>
<p>字典学习的目标，就是提取事物<strong>最本质的特征（类似于字典当中的字或词语）。</strong>如果我们能都获取这本包括<strong>最本质的特征</strong>的字典，那我们就掌握了这个事物的最本质的内涵。换言之，字典学习将我们的到的对于物体的信息降维，减少了该物体一些无关紧要信息对我们定义这个物体的干扰。</p>
<p><strong>模型建立：</strong></p>
<script type="math/tex; mode=display">
\pmb x = \sum_{i=1}^m \lambda_i\pmb w_i</script><p>$\lambda_i$称为表示系数，要求尽可能稀疏；$\pmb w_i$被称为”字典“。</p>
<p>问题是如何找到表示系数与字典？可转化为如下优化问题：</p>
<script type="math/tex; mode=display">
\min \sum_{i=1}^N||\pmb x_i - \sum_{j=1}^m y_{ij}\pmb w_j||^2 \\
s.t. ||\pmb y_i|| <= C</script><p>其中：$y$即为表示系数，约束条件对应要求表示系数尽可能稀疏。$m &gt;&gt;N$。</p>
<p>写成矩阵形式（有点类似非负矩阵分解形式，W是基，Y是系数）：</p>
<script type="math/tex; mode=display">
\min ||X - WY||^2\\
s.t.||Y|| <= C</script><p>由于上述优化问题含有两个优化变量，可采用坐标优化方法，即先固定系数$y$，求出最优的$\pmb w$；然后在求出系数。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      
      
    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2020/10/15/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80Lecture%203%E5%B1%80%E9%83%A8%E7%89%B9%E5%BE%81/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            机器视觉基础Lecture 3局部特征
          
        </div>
      </a>
    
    
      <a href="/2020/10/08/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E5%9F%BA%E7%A1%80Lecture%202/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">机器视觉基础Lecture 2</div>
      </a>
    
  </nav>


  

  

  
  
  

</article>
</section>
      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2019-2020
        张永剑
      </li>
      <li>
        
          Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <ul class="list-inline">
  <li>PV:<span id="busuanzi_value_page_pv"></span></li>
  <li>UV:<span id="busuanzi_value_site_uv"></span></li>
</ul>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
      <aside class="sidebar">
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="张永剑的博客"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>







<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer:'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
    onClick: (e) => {
      $('.toc-link').removeClass('is-active-link');
      $(`a[href=${e.target.hash}]`).addClass('is-active-link');
      $(e.target.hash).scrollIntoView();
      return false;
    }
  });
</script>


<script>
  var ayerConfig = {
    mathjax: true
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>



<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

</html>